{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "SHrMRXkBZXKY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from pprint import pprint\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYvYejypZfBl",
        "outputId": "9c13666e-04d3-4857-d7a2-e76f8ff87d3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-gpu==2.0.0-beta0\n",
        "clear_output()\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "ZFdwPnt-Zlz3"
      },
      "outputs": [],
      "source": [
        "# import logging\n",
        "# logging.basicConfig(level=\"error\")\n",
        "\n",
        "# np.set_printoptions(suppress=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "Z2I4V1niZngV"
      },
      "outputs": [],
      "source": [
        "ch_vocab_file = \"/content/drive/MyDrive/nycu/2022ML/translate/ml-2022-nycu-translation/ch_vocab_new\"\n",
        "tai_vocab_file = \"/content/drive/MyDrive/nycu/2022ML/translate/ml-2022-nycu-translation/tai_vocab_new\"\n",
        "checkpoint_path = \"/content/drive/MyDrive/nycu/2022ML/translate/ml-2022-nycu-translation/checkpoints_new\"\n",
        "log_dir = \"/content/drive/MyDrive/nycu/2022ML/translate/ml-2022-nycu-translation/logs\"\n",
        "download_dir = \"/content/drive/MyDrive/nycu/2022ML/translate/ml-2022-nycu-translation/tensorflow-datasets/downloads\"\n",
        "\n",
        "# if not os.path.exists(output_dir):\n",
        "#   os.makedirs(output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CI9D_hwTEHK",
        "outputId": "993a1689-9ad6-4840-d2d2-533ffc1576b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# from google drive import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "v3gF_O7kZk7V"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "w1-uuKjqVcRC"
      },
      "outputs": [],
      "source": [
        "del_list =[0]\n",
        "def processString(txt):\n",
        "  # specialChars = \"！#$%^&*()；，。ＥＣＦＡＢ、﹔、,＊《 」\" \n",
        "  # for specialChar in specialChars:\n",
        "  #   txt = txt.replace(specialChar,'')\n",
        "  #print(txt) # A,Quick,brown,fox,jumped,over,the,lazy,dog\n",
        "  #txt = txt.replace('-', ' ')\n",
        "  #print(txt) # A Quick brown fox jumped over the lazy dog \n",
        "  return txt \n",
        "def processString_ch(txt):\n",
        "  #specialChars = \"#$%^&*()（）⿰「」！、⿳；，。 ，,_。',、，。、'」「；！？：《》ＥＣＦＡＢ、﹔、,＊《 」\" #-123456789\n",
        "  specialChars = \" \"\n",
        "  for specialChar in specialChars:\n",
        "    txt = txt.replace(specialChar,'')\n",
        "  #print(txt) # A,Quick,brown,fox,jumped,over,the,lazy,dog\n",
        "  #print(txt) # A Quick brown fox jumped over the lazy dog \n",
        "  return txt "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KClyAfWPaGAE",
        "outputId": "e8f2541a-bddb-459d-9a79-d2beeefe584e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "my_re = re.compile(r'[a-zA-Z0-9_]')\n",
        "\n",
        "my_str_1 = '我是as誰'\n",
        "my_str_2 = '我是誰。'\n",
        "print(bool(re.search(my_re, my_str_1)))\n",
        "print(bool(re.search(my_re, my_str_2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHLrERWETG__",
        "outputId": "6176c4a9-0017-41d8-cc66-fcbe0bf17383"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 3, 5, 7, 11, 13, 15, 16, 17, 22, 24, 25, 31, 32, 33, 35, 65, 66, 165, 227, 231, 236, 240, 242, 246, 247, 252, 253, 254, 255, 256, 258, 260, 365, 370, 371, 374, 375, 376, 378, 379, 380, 454, 563, 591, 610, 611, 622, 625, 690, 706, 707, 709, 710, 712, 713, 717, 720, 721, 722, 723, 724, 727, 729, 731, 732, 733, 734, 735, 736, 737, 739, 740, 741, 742, 745, 747, 748, 749, 750, 751, 753, 754, 755, 756, 757, 761, 762, 811, 815, 819, 820, 824, 825, 846, 868, 870, 872, 874, 875, 876, 877, 878, 882, 884, 885, 894, 895, 898, 900, 907, 949, 950, 966, 967, 1085, 1091, 1161, 1164, 1166, 1167, 1172, 1173, 1174, 1177, 1178, 1184, 1185, 1186, 1188, 1190, 1191, 1194, 1224, 1266, 1282, 1284, 1389, 1393, 1394, 1399, 1402, 1403, 1405, 1415, 1427, 1429, 1431, 1463, 1467, 1470, 1472, 1473, 1477, 1483, 1485, 1487, 1490, 1622, 1624, 1626, 1628, 1631, 1632, 1633, 1637, 1638, 1639, 1640, 1642, 1644, 1645, 1648, 1649, 1650, 1651, 1652, 1654, 1655, 1656, 1658, 1660, 1662, 1663, 1664, 1666, 1670, 1671, 1674, 1675, 1685, 1690, 1691, 1692, 1700, 1792, 1794, 1795, 1798, 1805, 1807, 1811, 1813, 1904, 1915, 1917, 1920, 1924, 1930, 1932, 1977, 1978, 1985, 1991, 2128, 2130, 2133, 2134, 2137, 2144, 2146, 2150, 2156, 2158, 2160, 2162, 2165, 2166, 2171, 2174, 2177, 2181, 2182, 2184, 2186, 2188, 2197, 2198, 2200, 2222, 2359, 2398, 2402, 2403, 2409, 2411, 2412, 2413, 2417, 2419, 2420, 2421, 2425, 2426, 2433, 2471, 2549, 2554, 2558, 2565, 2569, 2572, 2673, 2675, 2684, 2908, 2912, 2923, 2931, 2980, 2983, 3001, 3002, 3004, 3080, 3082, 3084, 3085, 3087, 3091, 3097, 3098, 3101, 3102, 3103, 3109, 3254, 3260, 3263, 3273, 3285, 3287, 3288, 3289, 3292, 3295, 3301, 3302, 3310, 3312, 3313, 3317, 3320, 3324, 3326, 3334, 3340, 3344, 3345, 3359, 3514, 3628, 3675, 3688, 3728, 3730, 3734, 3737, 3746, 3749, 3771, 3979, 3998, 4001, 4005, 4007, 4009, 4013, 4014, 4018, 4027, 4032, 4043, 4050, 4051, 4053, 4059, 4063, 4066, 4069, 4071, 4075, 4082, 4083, 4084, 4087, 4101, 4103, 4108, 4142, 4153, 4154, 4171, 4184, 4185, 4261, 4271, 4272, 4279, 4281, 4291, 4356, 4358, 4359, 4361, 4366, 4367, 4368, 4372, 4378, 4379, 4384, 4389, 4439, 4448, 4560, 4567, 4598, 4599, 4633, 4644, 4646, 4648, 4654, 4658, 4665, 4671, 4681, 4687, 4808, 4819, 4827, 4828, 4837, 4838, 4843, 4890, 5163, 5170, 5171, 5178, 5188, 5351, 5353, 5354, 5355, 5357, 5362, 5375, 5378, 5381, 5382, 5384, 5390, 5399, 5402, 5410, 5415, 5417, 5443, 5446, 5538, 5548, 5551, 5796, 5805, 5807, 5824, 5848, 5851, 5887, 5893, 5902, 5905, 5908, 6003, 6021, 6023, 6045, 6046, 6052, 6053, 6054, 6056, 6057, 6096, 6118, 6122, 6123, 6126, 6131, 6132, 6134, 6136, 6140, 6142, 6144, 6147, 6336, 6574, 6679, 6739, 6961, 6967, 6979, 7063, 7067, 7073, 7080, 7085, 7117, 7118, 7152, 7223, 7231, 7278, 7294, 7330, 7344, 7346, 7355, 7360, 7363, 7375, 7405, 7413, 7414, 7416, 7419, 7420, 7423, 7430, 7431, 7433, 7448, 7673, 7705, 7757, 7764, 7778, 7783, 7801, 7845, 7937, 8052, 8125, 8131, 8160, 8164, 8232, 8234, 8236, 8243, 8247, 8249, 8252, 8258, 8288, 8290, 8297, 8300, 8304, 8308, 8313, 8314, 8319, 8322, 8323, 8324, 8327, 8330, 8331, 8338, 8341, 8348, 8351, 8355, 8356, 8361, 8366, 8368, 8369, 8371, 8372, 8627, 8634, 8843, 8875, 8892, 8894, 8899, 8900, 8908, 8911, 8912, 8914, 9129, 9133, 9225, 9229, 9232, 9236, 9241, 9243, 9245, 9246, 9248, 9252, 9254, 9255, 9256, 9260, 9262, 9263, 9267, 9280, 9798, 9815, 9849, 9850, 9852, 9902, 10010, 10022, 10030, 10033, 10035, 10039, 10050, 10058, 10064, 10065, 10134, 10136, 10148, 10154, 10161, 10169, 10176, 10187, 10198, 10292, 10339, 10395, 10397, 10402, 10422, 10494, 10502, 10517, 10519, 10596, 10599, 10601, 10604, 10607, 10608, 10614, 10648, 10653, 10688, 10693, 10942, 10944, 10948, 10952, 10957, 10960, 11024, 11028, 11054, 11111, 11141, 11233, 11235, 11240, 11244, 11247, 11251, 11253, 11281, 11285, 11293, 11300, 11302, 11464, 11468, 11711, 11792, 12123, 12241, 12685, 12923, 13114, 13271, 13273, 13280, 13302, 13304, 13314, 13328, 13351, 13384, 13425, 13430, 13476, 13541, 13578, 13584, 13590, 13668, 13669, 13682, 13722, 13842, 13854, 13858, 13875, 13932, 13947, 14006, 14112, 14330, 14347, 14372, 14374, 14386, 14498, 14606, 14733, 14750, 14878, 14884, 14887, 14895, 14906, 14913, 15274, 15419, 15424, 15462, 15479, 15498, 15499, 15633, 15638, 16053, 16058, 16095, 16471, 16473, 16481, 16487, 16531, 16781, 16930, 16982, 16986, 17126, 17244, 17253, 18197, 18204, 18211, 18212, 18217, 18228, 18295, 18305, 18309, 18314, 18367, 18372, 18374, 18377, 18378, 18381, 18461, 18497, 18734, 18840, 19438, 19509, 19529, 19606, 19910, 19967, 20320, 21059, 21065, 21389, 21392, 21841, 21845, 21850, 21881, 21889, 22440, 22444, 22446, 23054, 23735, 23742, 24613, 24621, 24675, 24679, 24682, 24684, 24686, 24691, 24692, 24697, 24701, 24704, 24737, 25387, 25401, 25516, 25518, 25526, 25527, 26163, 26190, 26722, 26732, 26952, 26997, 27066, 27280, 27636, 27842, 27881, 27883, 28117, 28574, 28619, 28638, 28731, 28893, 29309, 30231, 30248, 30255, 30257, 30258, 30293, 30295, 30303, 30308, 30309, 30320, 30526, 31366, 31862, 32073, 32084, 32246, 32300, 32412, 32585, 33771, 33784, 33834, 33837, 33852, 34574, 34581, 34589, 35477, 35480, 35482, 35487, 35497, 35998, 36008, 36018, 36089, 36102, 36437, 36455, 36495, 36506, 36688, 36700, 37489, 37587, 37603, 37651, 37805, 37847, 37854, 37861, 37863, 38888, 38905, 39444, 40156, 40161, 40168, 40174, 40683, 40689, 40695, 40698, 40990, 41088, 41260, 41262, 41272, 41382, 41505, 41509, 41517, 41525, 41674, 41676, 41680, 41681, 41697, 41698, 41699, 41701, 42267, 42346, 42442, 42458, 42555, 42560, 42567, 42571, 43620, 43622, 43626, 43628, 43632, 43636, 43638, 43640, 43643, 43654, 43669, 44026, 44037, 44055, 44263, 44269, 44306, 44321, 44339, 44622, 44690, 44693, 44696, 44701, 44705, 44712, 44713, 45795, 45813, 45814, 45836, 46083, 46093, 46097, 46105, 46273, 46282, 46402, 46406, 46408, 46411, 46413, 46418, 46420, 46422, 46624, 47003, 47007, 47024, 47142, 47146, 47658, 47761, 47762, 47773, 47847, 47863, 47866, 47872, 47874, 47875, 47876, 48489, 48495, 48503, 49037, 49043, 49058, 49110, 49362, 49389, 49401, 49404, 49407, 49410, 49413, 49415, 49417, 49418, 49421, 49422, 49423, 49425, 49445, 49634, 49636, 49640, 49646, 49647, 49654, 49656, 49657, 49658, 49701, 50105, 51004, 51007, 51028, 51122, 51256, 51831, 52002, 52403, 52406, 52410, 52411, 52754, 52755, 52757, 52769, 52927, 52934, 52943, 53522, 53527, 53538, 53539, 54197, 55203, 55217, 55219, 55456, 55486, 55497, 55712, 55723, 55727, 56412, 56752, 57787, 57795, 59041, 59045, 59051, 59056, 59305, 59315, 59321, 59656, 59669, 59675, 59872, 60047, 60049, 60065, 60079, 60093, 60547, 61288, 61552, 61761, 61846, 61957, 62243]\n",
            "62424\n",
            "2423\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "data_path = \"/content/drive/MyDrive/nycu/2022ML/translate/ml-2022-nycu-translation/\"\n",
        "train_y_path = \"/content/drive/MyDrive/nycu/2022ML/translate/ml-2022-nycu-translation/train-TL.csv\"\n",
        "train_x_path = \"/content/drive/MyDrive/nycu/2022ML/translate/ml-2022-nycu-translation/train-ZH.csv\"\n",
        "test_x_path = \"/content/drive/MyDrive/nycu/2022ML/translate/ml-2022-nycu-translation/test-ZH-nospace.csv\"\n",
        "train_path = \"/content/drive/MyDrive/nycu/2022ML/translate/ml-2022-nycu-translation/train_translate.csv\"\n",
        "valid_path = \"/content/drive/MyDrive/nycu/2022ML/translate/ml-2022-nycu-translation/valid_translate.csv\"\n",
        "# wavs_path = data_path + \"/train/new/\"\n",
        "# metadata_path = data_path + \"/train-toneless.csv\"\n",
        "\n",
        "\n",
        "# Read metadata file and parse it\n",
        "train_x = pd.read_csv(train_x_path, sep=\",\", header=None)#, quoting=2\n",
        "#metadata_df.head(3)\n",
        "train_x.columns = [\"id\", \"txt\"]\n",
        "train_x = train_x[[\"id\", \"txt\"]]\n",
        "#train_x = train_x.drop(0)\n",
        "count = 0;\n",
        "for index,row in train_x.iterrows():\n",
        "  id = row[\"id\"]\n",
        "  txt = row[\"txt\"]\n",
        "  row[\"txt\"] = processString_ch(txt)\n",
        "  if(bool(re.search(my_re, txt))and count not in del_list):# \n",
        "    del_list.append(count)\n",
        "  count = count+1;\n",
        "print(del_list)\n",
        "train_x = train_x.drop(del_list)\n",
        "# data_df = metadata_df.drop(del_list)\n",
        "# print(data_df.shape)\n",
        "\n",
        "#train_xx = train_x.iloc[:60000]\n",
        "train_xx = train_x\n",
        "valid_x = train_x.iloc[60001:]\n",
        "#train_y = train_y.sample(frac=1)#.reset_index(drop=True)\n",
        "#train_y.head(3)\n",
        "context_raw = train_xx[\"txt\"].values\n",
        "valid_x = valid_x[\"txt\"].values\n",
        "print(len(context_raw))\n",
        "print(len(valid_x))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "joL6v0p2XBYK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-oRkUZFsLhz",
        "outputId": "95201713-8515-4cfc-addb-69fc724368f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62424\n",
            "2423\n"
          ]
        }
      ],
      "source": [
        "# Read metadata file and parse it\n",
        "train_y = pd.read_csv(train_y_path, sep=\",\", header=None)#, quoting=2\n",
        "#metadata_df.head(3)\n",
        "\n",
        "train_y.columns = [\"id\", \"txt\"]\n",
        "train_y = train_y[[\"id\", \"txt\"]]\n",
        "#train_y = train_y.drop(0)\n",
        "\n",
        "# count = 0;\n",
        "# for index,row in train_y.iterrows():\n",
        "#   id = row[\"id\"]\n",
        "#   text = row[\"text\"]\n",
        "#   if((text.islower()==False) and int(id) not in del_list):\n",
        "#     del_list.append(count)\n",
        "#   else:\n",
        "#     for chara in text:\n",
        "#       if (chara not in lexicon_list )and chara.isalpha():\n",
        "#         del_list.append(count)\n",
        "#   count = count+1;\n",
        "# print(del_list)\n",
        "\n",
        "# data_df = metadata_df.drop(del_list)\n",
        "# print(data_df.shape)\n",
        "for index,row in train_y.iterrows():\n",
        "  id = row[\"id\"]\n",
        "  txt = row[\"txt\"]\n",
        "  row[\"txt\"] = processString(txt)\n",
        "  #print(row[\"txt\"])\n",
        "\n",
        "\n",
        "# for index,row in train_y.iterrows():\n",
        "#   print(row[\"txt\"])\n",
        "train_y = train_y.drop(del_list)\n",
        "\n",
        "#train_yy = train_y.iloc[:60000]\n",
        "train_yy = train_y\n",
        "valid_y = train_y.iloc[60001:]\n",
        "#train_y = train_y.sample(frac=1)#.reset_index(drop=True)\n",
        "#train_y.head(3)\n",
        "target_raw = train_yy[\"txt\"].values\n",
        "valid_y = valid_y[\"txt\"].values\n",
        "print(len(target_raw))\n",
        "print(len(valid_y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "4XtwguTQC2B2"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "train_x = pd.read_csv(train_x_path, sep=\",\", header=None)\n",
        "train_y = pd.read_csv(train_x_path, sep=\",\", header=None)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/nycu/2022ML/translate/ml-2022-nycu-translation/train_translate.csv\", 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow(['ch', 'tw'])\n",
        "    for x,y in zip (context_raw,target_raw):\n",
        "        writer.writerow([x,y])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "pzrWkpAdMnIp"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "train_x = pd.read_csv(train_x_path, sep=\",\", header=None)\n",
        "train_y = pd.read_csv(train_x_path, sep=\",\", header=None)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/nycu/2022ML/translate/ml-2022-nycu-translation/valid_translate.csv\", 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow(['ch', 'tw'])\n",
        "    for x,y in zip (valid_x,valid_y):\n",
        "        writer.writerow([x,y])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "PAGlKUbjC2Fa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IViDFU184eDI",
        "outputId": "d7963ec6-d734-4e92-a6e9-04074be2586e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<CsvDatasetV2 element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.string, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "train_examples = tf.data.experimental.CsvDataset(\n",
        "  train_path,\n",
        "  [\n",
        "   tf.string,tf.string  # Required field, use dtype or empty tensor\n",
        "  ],\n",
        "  header = True,\n",
        "  select_cols=[0,1]  # Only parse last three columns\n",
        ")\n",
        "train_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rInUWPdbNK1y",
        "outputId": "aa4c431d-338c-48a7-fa80-c4212c540dbf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<CsvDatasetV2 element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.string, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ],
      "source": [
        "val_examples = tf.data.experimental.CsvDataset(\n",
        "  valid_path,\n",
        "  [\n",
        "   tf.string,tf.string  # Required field, use dtype or empty tensor\n",
        "  ],\n",
        "  header = True,\n",
        "  select_cols=[0,1]  # Only parse last three columns\n",
        ")\n",
        "val_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-EgrkAJ3ubP",
        "outputId": "387c7592-3faa-4ec7-d685-0fc87339b0e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(b'\\xe9\\xa7\\x90\\xe7\\xbe\\x8e\\xe7\\x89\\xb9\\xe6\\xb4\\xbe\\xe5\\x93\\xa1\\xe6\\x9b\\xb9\\xe9\\x83\\x81\\xe8\\x8a\\xac\\xe8\\x8f\\xaf\\xe5\\xba\\x9c\\xe5\\xa0\\xb1\\xe5\\xb0\\x8e', b'tsu3-bi2 tik8-phai3-uan5 tso5-hiok4-hun1 hua5-hu2 po3-to7')\n"
          ]
        }
      ],
      "source": [
        "for element in train_examples.as_numpy_iterator():\n",
        "  print(element)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "uMpUZDI8xAc3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm36oySicJU2",
        "outputId": "030bd47a-5a5a-446b-d299-c8b2b246903b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'\\xe9\\xa7\\x90\\xe7\\xbe\\x8e\\xe7\\x89\\xb9\\xe6\\xb4\\xbe\\xe5\\x93\\xa1\\xe6\\x9b\\xb9\\xe9\\x83\\x81\\xe8\\x8a\\xac\\xe8\\x8f\\xaf\\xe5\\xba\\x9c\\xe5\\xa0\\xb1\\xe5\\xb0\\x8e', shape=(), dtype=string)\n",
            "tf.Tensor(b'tsu3-bi2 tik8-phai3-uan5 tso5-hiok4-hun1 hua5-hu2 po3-to7', shape=(), dtype=string)\n",
            "----------\n",
            "tf.Tensor(b'\\xe5\\xa3\\x93\\xe5\\x80\\x92\\xe6\\x80\\xa7\\xe5\\x8b\\x9d\\xe5\\x88\\xa9\\xe5\\x89\\xb5\\xe9\\x80\\xa0\\xe6\\x96\\xb0\\xe6\\xad\\xb7\\xe5\\x8f\\xb2', shape=(), dtype=string)\n",
            "tf.Tensor(b'ap4-to2-sing3 sing3-li7 tshong3-tso7 sin1-lik8-su2', shape=(), dtype=string)\n",
            "----------\n",
            "tf.Tensor(b'\\xe7\\x95\\xb6\\xe9\\x81\\xb8\\xe7\\xbe\\x8e\\xe5\\x9c\\x8b\\xe6\\xad\\xb7\\xe5\\x8f\\xb2\\xe4\\xb8\\x8a\\xe9\\xa0\\xad\\xe4\\xb8\\x80\\xe4\\xbd\\x8d\\xe7\\x83\\x8f\\xe4\\xba\\xba\\xe7\\xb8\\xbd\\xe7\\xb5\\xb1', shape=(), dtype=string)\n",
            "tf.Tensor(b'tong3-suan2 bi2-kok4 lik8-su2 siong7 thau5-tsit8-ui7 oo1-lang5 tsong2-thong2', shape=(), dtype=string)\n",
            "----------\n"
          ]
        }
      ],
      "source": [
        "for en, zh in train_examples.take(3):\n",
        "  print(en)\n",
        "  print(zh)\n",
        "  print('-' * 10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0TrsxIxcLtQ",
        "outputId": "4b18ead8-783d-4628-acd4-22b8e1c17af2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "駐美特派員曹郁芬華府報導\n",
            "tsu3-bi2 tik8-phai3-uan5 tso5-hiok4-hun1 hua5-hu2 po3-to7\n",
            "----------\n",
            "壓倒性勝利創造新歷史\n",
            "ap4-to2-sing3 sing3-li7 tshong3-tso7 sin1-lik8-su2\n",
            "----------\n",
            "當選美國歷史上頭一位烏人總統\n",
            "tong3-suan2 bi2-kok4 lik8-su2 siong7 thau5-tsit8-ui7 oo1-lang5 tsong2-thong2\n",
            "----------\n",
            "對著二十偌萬支持者宣告\n",
            "tui3-tioh8 ji7-tsap8 jua7 ban7 tsi1-tshi5-tsia2 suan1-ko3\n",
            "----------\n",
            "改變已經來到美國\n",
            "kai2-pian3 i2-king1 lai5-kau3 bi2-kok4\n",
            "----------\n",
            "佇已經開出的選票中\n",
            "ti7 i2-king1 khui1-tshut4 e5 suan2-phio3 tiong1\n",
            "----------\n",
            "（大概六千兩百九十六萬票）的普選票\n",
            "( tai7-khai3 lak8-tshing1-nng7-pah4-kau2-tsap8-lak8 ban7 phio3 ) e5 phoo2-suan2 phio3\n",
            "----------\n",
            "（大概五千五百七十六萬票）\n",
            "( tai7-khai3 goo7-tshing1-goo7-pah4-tshit4-tsap8-lak8 ban7 phio3 )\n",
            "----------\n",
            "將佇明年一月二十日宣誓就職\n",
            "tsiong1-ti7 me5-ni5 it4-geh8 ji7-tsap8 jit8 suan1-se3-tsiu7-tsit4\n",
            "----------\n",
            "成為美國第四十四屆總統\n",
            "sing5-ui5 bi2-kok4 te7-si3-tsap8-si3 kai3 tsong2-thong2\n",
            "----------\n"
          ]
        }
      ],
      "source": [
        "sample_examples = []\n",
        "num_samples = 10\n",
        "\n",
        "for ch_t, zh_t in train_examples.take(num_samples):\n",
        "  ch = ch_t.numpy().decode(\"utf-8\")\n",
        "  zh = zh_t.numpy().decode(\"utf-8\")\n",
        "  \n",
        "  print(ch)\n",
        "  print(zh)\n",
        "  print('-' * 10)\n",
        "  \n",
        "  # 之後用來簡單評估模型的訓練情況\n",
        "  sample_examples.append((ch, zh))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3N-W0I9Ygn5i",
        "outputId": "0496e355-69f4-4217-92d9-26b44c3914ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "載入已建立的字典： /content/drive/MyDrive/nycu/2022ML/translate/ml-2022-nycu-translation/ch_vocab_new\n",
            "字典大小：8435\n",
            "前 10 個 subwords：['，', '。', '的', '民視新聞報導', '佇', '、', '無', '大', '佮', '人']\n",
            "\n",
            "CPU times: user 82.9 ms, sys: 3.88 ms, total: 86.7 ms\n",
            "Wall time: 157 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "try:\n",
        "  subword_encoder_ch = tfds.deprecated.text.SubwordTextEncoder.load_from_file(ch_vocab_file)\n",
        "  print(f\"載入已建立的字典： {ch_vocab_file}\")\n",
        "except:\n",
        "  print(\"沒有已建立的字典，從頭建立。\")\n",
        "  subword_encoder_ch = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "      (en.numpy() for en, _ in train_examples), \n",
        "      target_vocab_size=2**13) # 有需要可以調整字典大小\n",
        "  \n",
        "  # 將字典檔案存下以方便下次 warmstart\n",
        "  subword_encoder_ch.save_to_file(ch_vocab_file)\n",
        "  \n",
        "\n",
        "print(f\"字典大小：{subword_encoder_ch.vocab_size}\")\n",
        "print(f\"前 10 個 subwords：{subword_encoder_ch.subwords[:10]}\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhziYhn_cf4q",
        "outputId": "f247aca6-dc86-44da-8f77-1c05e31e4465"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 6516, 146, 3858, 1672]"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ],
      "source": [
        "sample_string = '佇菜園種有機青菜'\n",
        "indices = subword_encoder_ch.encode(sample_string)\n",
        "indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3kpYb0Nch5t",
        "outputId": "9409b740-90fc-4e78-c6ad-c5413e2e6520"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index     Subword\n",
            "---------------\n",
            "    5     佇\n",
            " 6516     菜園\n",
            "  146     種\n",
            " 3858     有機\n",
            " 1672     青菜\n"
          ]
        }
      ],
      "source": [
        "print(\"{0:10}{1:6}\".format(\"Index\", \"Subword\"))\n",
        "print(\"-\" * 15)\n",
        "for idx in indices:\n",
        "  subword = subword_encoder_ch.decode([idx])\n",
        "  print('{0:5}{1:6}'.format(idx, ' ' * 5 + subword))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHL4iUrvcjXP",
        "outputId": "76e2bb7d-fbef-4540-a98a-1edb9944d8c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('佇菜園種有機青菜', '佇菜園種有機青菜')\n"
          ]
        }
      ],
      "source": [
        "sample_string = '佇菜園種有機青菜'\n",
        "indices = subword_encoder_ch.encode(sample_string)\n",
        "decoded_string = subword_encoder_ch.decode(indices)\n",
        "assert decoded_string == sample_string\n",
        "pprint((sample_string, decoded_string))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mx4Tb2bclT5",
        "outputId": "ffae9ef9-fa8e-4c17-be3e-054876e52e5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "載入已建立的字典： /content/drive/MyDrive/nycu/2022ML/translate/ml-2022-nycu-translation/tai_vocab_new\n",
            "字典大小：299\n",
            "前 10 個 subwords：['，', '。', '、', '；', '」', '「', '！', '？', '：', '）']\n",
            "\n",
            "CPU times: user 6.93 ms, sys: 4.12 ms, total: 11.1 ms\n",
            "Wall time: 16.1 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "try:\n",
        "  subword_encoder_zh = tfds.deprecated.text.SubwordTextEncoder.load_from_file(tai_vocab_file)\n",
        "  print(f\"載入已建立的字典： {tai_vocab_file}\")\n",
        "except:\n",
        "  print(\"沒有已建立的字典，從頭建立。\")\n",
        "  subword_encoder_zh = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "      (zh.numpy() for _, zh in train_examples), \n",
        "      target_vocab_size=2**13, # 有需要可以調整字典大小\n",
        "      max_subword_length=1) # 每一個台語字就是字典裡的一個單位\n",
        "  \n",
        "  # 將字典檔案存下以方便下次 warmstart \n",
        "  subword_encoder_zh.save_to_file(tai_vocab_file)\n",
        "\n",
        "print(f\"字典大小：{subword_encoder_zh.vocab_size}\")\n",
        "print(f\"前 10 個 subwords：{subword_encoder_zh.subwords[:10]}\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuacbPm3cm0E",
        "outputId": "a5ecaca4-fa05-431c-d1a7-c40294fef47f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tsu3-bi2 tik8-phai3-uan5 tso5-hiok4-hun1 hua5-hu2 po3-to7\n",
            "[159, 158, 160, 94, 88, 141, 148, 93, 75, 159, 148, 150, 99, 88, 155, 147, 140, 148, 94, 88, 160, 140, 153, 96, 75, 159, 158, 154, 96, 88, 147, 148, 154, 150, 95, 88, 147, 160, 153, 92, 75, 147, 160, 140, 96, 88, 147, 160, 93, 75, 155, 154, 94, 88, 159, 154, 98]\n"
          ]
        }
      ],
      "source": [
        "sample_string = sample_examples[0][1]\n",
        "indices = subword_encoder_zh.encode(sample_string)\n",
        "print(sample_string)\n",
        "print(indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF0peTeLcohF",
        "outputId": "b6f85ffe-92e8-4856-90c0-9273b55b50d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[中台原文]（轉換前）\n",
            "tf.Tensor(b'\\xe7\\x95\\xb6\\xe9\\x81\\xb8\\xe7\\xbe\\x8e\\xe5\\x9c\\x8b\\xe6\\xad\\xb7\\xe5\\x8f\\xb2\\xe4\\xb8\\x8a\\xe9\\xa0\\xad\\xe4\\xb8\\x80\\xe4\\xbd\\x8d\\xe7\\x83\\x8f\\xe4\\xba\\xba\\xe7\\xb8\\xbd\\xe7\\xb5\\xb1', shape=(), dtype=string)\n",
            "ti7 tshai3-hng5 tsing3 iu2-ki1-tshenn1-tshai3\n",
            "\n",
            "--------------------\n",
            "\n",
            "[中台序列]（轉換後）\n",
            "[5, 6516, 146, 3858, 1672]\n",
            "[159, 148, 98, 75, 159, 158, 147, 140, 148, 94, 88, 147, 153, 146, 96, 75, 159, 158, 148, 153, 146, 94, 75, 148, 160, 93, 88, 150, 148, 92, 88, 159, 158, 147, 144, 153, 153, 92, 88, 159, 158, 147, 140, 148, 94]\n"
          ]
        }
      ],
      "source": [
        "ch = \"佇菜園種有機青菜\"\n",
        "zh = \"ti7 tshai3-hng5 tsing3 iu2-ki1-tshenn1-tshai3\"\n",
        "\n",
        "# 將文字轉成為 subword indices\n",
        "ch_indices = subword_encoder_ch.encode(ch)\n",
        "zh_indices = subword_encoder_zh.encode(zh)\n",
        "\n",
        "print(\"[中台原文]（轉換前）\")\n",
        "print(en)\n",
        "print(zh)\n",
        "print()\n",
        "print('-' * 20)\n",
        "print()\n",
        "print(\"[中台序列]（轉換後）\")\n",
        "print(ch_indices)\n",
        "print(zh_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "MpMLKw5ecqYh"
      },
      "outputs": [],
      "source": [
        "def encode(ch_t, zh_t):\n",
        "  # 因為字典的索引從 0 開始，\n",
        "  # 我們可以使用 subword_encoder_ch.vocab_size 這個值作為 BOS 的索引值\n",
        "  # 用 subword_encoder_ch.vocab_size + 1 作為 EOS 的索引值\n",
        "  ch_indices = [subword_encoder_ch.vocab_size] + subword_encoder_ch.encode(\n",
        "      ch_t.numpy()) + [subword_encoder_ch.vocab_size + 1]\n",
        "  # 同理，不過是使用台語字典的最後一個索引 + 1\n",
        "  zh_indices = [subword_encoder_zh.vocab_size] + subword_encoder_zh.encode(\n",
        "      zh_t.numpy()) + [subword_encoder_zh.vocab_size + 1]\n",
        "  \n",
        "  return ch_indices, zh_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUTjf2oEcsB1",
        "outputId": "dcf9a769-75ed-4d53-93bf-61176c90c455"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "中文 BOS 的 index： 8435\n",
            "中文 EOS 的 index： 8436\n",
            "台語 BOS 的 index： 299\n",
            "台語 EOS 的 index： 300\n",
            "\n",
            "輸入為 2 個 Tensors：\n",
            "(<tf.Tensor: shape=(), dtype=string, numpy=b'\\xe9\\xa7\\x90\\xe7\\xbe\\x8e\\xe7\\x89\\xb9\\xe6\\xb4\\xbe\\xe5\\x93\\xa1\\xe6\\x9b\\xb9\\xe9\\x83\\x81\\xe8\\x8a\\xac\\xe8\\x8f\\xaf\\xe5\\xba\\x9c\\xe5\\xa0\\xb1\\xe5\\xb0\\x8e'>,\n",
            " <tf.Tensor: shape=(), dtype=string, numpy=b'tsu3-bi2 tik8-phai3-uan5 tso5-hiok4-hun1 hua5-hu2 po3-to7'>)\n",
            "---------------\n",
            "輸出為 2 個索引序列：\n",
            "([8435,\n",
            "  2291,\n",
            "  421,\n",
            "  717,\n",
            "  1291,\n",
            "  256,\n",
            "  8409,\n",
            "  8334,\n",
            "  8364,\n",
            "  8412,\n",
            "  8310,\n",
            "  8308,\n",
            "  6089,\n",
            "  4336,\n",
            "  531,\n",
            "  8436],\n",
            " [299,\n",
            "  159,\n",
            "  158,\n",
            "  160,\n",
            "  94,\n",
            "  88,\n",
            "  141,\n",
            "  148,\n",
            "  93,\n",
            "  75,\n",
            "  159,\n",
            "  148,\n",
            "  150,\n",
            "  99,\n",
            "  88,\n",
            "  155,\n",
            "  147,\n",
            "  140,\n",
            "  148,\n",
            "  94,\n",
            "  88,\n",
            "  160,\n",
            "  140,\n",
            "  153,\n",
            "  96,\n",
            "  75,\n",
            "  159,\n",
            "  158,\n",
            "  154,\n",
            "  96,\n",
            "  88,\n",
            "  147,\n",
            "  148,\n",
            "  154,\n",
            "  150,\n",
            "  95,\n",
            "  88,\n",
            "  147,\n",
            "  160,\n",
            "  153,\n",
            "  92,\n",
            "  75,\n",
            "  147,\n",
            "  160,\n",
            "  140,\n",
            "  96,\n",
            "  88,\n",
            "  147,\n",
            "  160,\n",
            "  93,\n",
            "  75,\n",
            "  155,\n",
            "  154,\n",
            "  94,\n",
            "  88,\n",
            "  159,\n",
            "  154,\n",
            "  98,\n",
            "  300])\n"
          ]
        }
      ],
      "source": [
        "ch_t, zh_t = next(iter(train_examples))\n",
        "ch_indices, zh_indices = encode(ch_t, zh_t)\n",
        "print('中文 BOS 的 index：', subword_encoder_ch.vocab_size)\n",
        "print('中文 EOS 的 index：', subword_encoder_ch.vocab_size + 1)\n",
        "print('台語 BOS 的 index：', subword_encoder_zh.vocab_size)\n",
        "print('台語 EOS 的 index：', subword_encoder_zh.vocab_size + 1)\n",
        "\n",
        "print('\\n輸入為 2 個 Tensors：')\n",
        "pprint((ch_t, zh_t))\n",
        "print('-' * 15)\n",
        "print('輸出為 2 個索引序列：')\n",
        "pprint((ch_indices, zh_indices))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "HuwTmTOHQjq8"
      },
      "outputs": [],
      "source": [
        "# from typing import Union\n",
        "# import tensorflow as tf\n",
        "\n",
        "\n",
        "# def np_function(input_signature: Union[tuple, list], type_out: Union[tuple, list]):\n",
        "#     \"\"\"\n",
        "#     It takes a function and returns a function that takes a tensor as input and returns a tensor as output\n",
        "\n",
        "#     Args:\n",
        "#       input_signature: This is the input signature list of the function. It is a list of TensorSpec objects.\n",
        "#       type_out: The output types of the function.\n",
        "\n",
        "#     Returns:\n",
        "#       A decorator that takes a function and returns a wrapper function.\n",
        "#     \"\"\"\n",
        "#     if type_out is None:\n",
        "#         raise TypeError(\"You must provide output types as a list or a tuple!\")\n",
        "\n",
        "#     def map_decorator(func):\n",
        "#         @tf.function(input_signature=input_signature)\n",
        "#         def wrapper( *args):\n",
        "#             return tf.numpy_function(func, inp=args, Tout=type_out)\n",
        "\n",
        "#         return wrapper\n",
        "\n",
        "#     return map_decorator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "Z4jCYCrqQ-ss"
      },
      "outputs": [],
      "source": [
        "# from mytools import np_function\n",
        "\n",
        "# @np_function(input_signature=[tf.TensorSpec(shape=None, dtype=tf.string)], type_out=[tf.float32, tf.uint8])\n",
        "# def load_data(file_name):  # get numpy types here\n",
        "#     file_name = file_name.decode(\"utf8\")  # 直接使用数据\n",
        "#     label = label_dict[pattern.search(file_name).group(0)]\n",
        "#     data = np.loadtxt(file_name)[..., np.newaxis]\n",
        "#     return tf.cast(data, tf.float32), tf.cast(label, tf.uint8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "f4gHHjjnbhz2"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "\n",
        "# x = tf.Variable(initial_value=3.)\n",
        "# with tf.GradientTape() as tape:     # 在 tf.GradientTape() 的上下文內，所有計算步驟都會被記錄以用於推導\n",
        "#     y = tf.square(x)\n",
        "# y_grad = tape.gradient(y, x)        # 計算y關於x的導數\n",
        "# print(y, y_grad)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmsfqdvPcvTP",
        "outputId": "5b856f9a-a4e7-4560-fc1a-098723b5c10d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[8435 2291  421  717 1291  256 8409 8334 8364 8412 8310 8308 6089 4336\n",
            "  531 8436], shape=(16,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[299 159 158 160  94  88 141 148  93  75 159 148 150  99  88 155 147 140\n",
            " 148  94  88 160 140 153  96  75 159 158 154  96  88 147 148 154 150  95\n",
            "  88 147 160 153  92  75 147 160 140  96  88 147 160  93  75 155 154  94\n",
            "  88 159 154  98 300], shape=(59,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "def tf_encode(ch_t, zh_t):\n",
        "  # 在 `tf_encode` 函式裡頭的 `ch_t` 與 `zh_t` 都不是 Eager Tensors\n",
        "  # 要到 `tf.py_funtion` 裡頭才是\n",
        "  # 另外因為索引都是整數，所以使用 `tf.int64`\n",
        "  return tf.py_function(encode, [ch_t, zh_t], [tf.int64, tf.int64])\n",
        "\n",
        "# `tmp_dataset` 為說明用資料集，說明完所有重要的 func，\n",
        "# 我們會從頭建立一個正式的 `train_dataset`\n",
        "tmp_dataset = train_examples.map(tf_encode)\n",
        "ch_indices, zh_indices = next(iter(tmp_dataset))\n",
        "print(ch_indices)\n",
        "print(zh_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "qGG3Z6e0cxvh"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 40\n",
        "\n",
        "def filter_max_length(ch, zh, max_length=MAX_LENGTH):\n",
        "  # ch, zh 分別代表中文和台語的索引序列\n",
        "  return tf.logical_and(tf.size(ch) <= max_length,\n",
        "                        tf.size(zh) <= max_length)\n",
        "\n",
        "# tf.data.Dataset.filter(func) 只會回傳 func 為真的例子\n",
        "tmp_dataset = tmp_dataset.filter(filter_max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IB3hygl3c11Z",
        "outputId": "bb1b0a01-deb4-483a-cc32-533cc5221507"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "中文索引序列的 batch\n",
            "tf.Tensor(\n",
            "[[8435 2262   42  274  397 8436    0    0    0    0    0]\n",
            " [8435  397 1005    8 1603 1649 8436    0    0    0    0]\n",
            " [8435  122  457 1819   17 8010 8436    0    0    0    0]\n",
            " [8435 2661  225 3097 8436    0    0    0    0    0    0]\n",
            " [8435  397  314  242  323  715 3478 8436    0    0    0]\n",
            " [8435 3477   12 6094  656 4015  120 8436    0    0    0]\n",
            " [8435  108 2576 1753 2558    1 8436    0    0    0    0]\n",
            " [8435 2827 3211    1 8436    0    0    0    0    0    0]\n",
            " [8435  307  692 2662    2 8436    0    0    0    0    0]\n",
            " [8435   16 1448 6281   61 1568    1 8436    0    0    0]\n",
            " [8435   36   57  295 7975    2 8436    0    0    0    0]\n",
            " [8435 3199 8409 8338 8311 1220   46    1 8436    0    0]\n",
            " [8435   40  232  438  202  117    1 8436    0    0    0]\n",
            " [8435 1893  975  249 1075   45    1 8436    0    0    0]\n",
            " [8435   40  183 1444 3507  975  249    1 8436    0    0]\n",
            " [8435   57   37  574    7 1522    1 8436    0    0    0]\n",
            " [8435 4488  228  232  323    1 8436    0    0    0    0]\n",
            " [8435 6546 5568 7536    1 8436    0    0    0    0    0]\n",
            " [8435   80  518    1 8436    0    0    0    0    0    0]\n",
            " [8435  448    1 8436    0    0    0    0    0    0    0]\n",
            " [8435  182 1554 2153    1 8436    0    0    0    0    0]\n",
            " [8435  110 1887 1276  466    1 8436    0    0    0    0]\n",
            " [8435 3654 7995 2471   10    1 8436    0    0    0    0]\n",
            " [8435   80  303    1 8436    0    0    0    0    0    0]\n",
            " [8435 5364    1 8436    0    0    0    0    0    0    0]\n",
            " [8435  267  253    1 8436    0    0    0    0    0    0]\n",
            " [8435 1897 4605 2066 6000    2 8436    0    0    0    0]\n",
            " [8435 4852  812   17   29 2835 8436    0    0    0    0]\n",
            " [8435   71   29    1 8436    0    0    0    0    0    0]\n",
            " [8435   71   77 6341   17   77    1 8436    0    0    0]\n",
            " [8435 7963 7963  361  340    1 8436    0    0    0    0]\n",
            " [8435 1429 3983 7056    1 8436    0    0    0    0    0]\n",
            " [8435 1835 8436    0    0    0    0    0    0    0    0]\n",
            " [8435  397 3531 2741 3109    1 8436    0    0    0    0]\n",
            " [8435 2227  107 6342    6 8436    0    0    0    0    0]\n",
            " [8435 1900   17   12 6410 1834 6409  315   22 3354 8436]\n",
            " [8435  131    1 8436    0    0    0    0    0    0    0]\n",
            " [8435  801  758  742    1 8436    0    0    0    0    0]\n",
            " [8435 2074 5860 2982    1 8436    0    0    0    0    0]\n",
            " [8435  769 1182   64 7354    1 8436    0    0    0    0]\n",
            " [8435  649  646 2239    2 8436    0    0    0    0    0]\n",
            " [8435  235  591   29    1 8436    0    0    0    0    0]\n",
            " [8435 2596 1713 2173  587    1 8436    0    0    0    0]\n",
            " [8435   39  202   64  532    1 8436    0    0    0    0]\n",
            " [8435  504 5155  263 8436    0    0    0    0    0    0]\n",
            " [8435    4 8436    0    0    0    0    0    0    0    0]\n",
            " [8435   65  658  125  323    1 8436    0    0    0    0]\n",
            " [8435 4613  511  282 1104    1 8436    0    0    0    0]\n",
            " [8435 4613    3 3404    1 8436    0    0    0    0    0]\n",
            " [8435 2176   85 1092 1392  285    1 8436    0    0    0]\n",
            " [8435 3850  531 8436    0    0    0    0    0    0    0]\n",
            " [8435  191 1528  402    1 8436    0    0    0    0    0]\n",
            " [8435 3660  149 6587 2292    1 8436    0    0    0    0]\n",
            " [8435  538   96 4056 8409 8342 8318    1 8436    0    0]\n",
            " [8435 6799 2134 1251   64 2499  263 8436    0    0    0]\n",
            " [8435 1835 8436    0    0    0    0    0    0    0    0]\n",
            " [8435  500 1206    3 4774    1 8436    0    0    0    0]\n",
            " [8435 2965  519  246    1 8436    0    0    0    0    0]\n",
            " [8435  210  682    1 8436    0    0    0    0    0    0]\n",
            " [8435  295 4706    7 1228  463    1 8436    0    0    0]\n",
            " [8435   22  678 2714    1 8436    0    0    0    0    0]\n",
            " [8435  139  586  300  114  695    1 8436    0    0    0]\n",
            " [8435  362  851 1663   51    1 8436    0    0    0    0]\n",
            " [8435  299  267 4629    2 8436    0    0    0    0    0]], shape=(64, 11), dtype=int64)\n",
            "--------------------\n",
            "台語索引序列的 batch\n",
            "tf.Tensor(\n",
            "[[299 150 140 ... 150  95 300]\n",
            " [299 141 148 ... 146  98 300]\n",
            " [299 147 144 ...   0   0   0]\n",
            " ...\n",
            " [299 160 148 ...   0   0   0]\n",
            " [299 147 140 ...   0   0   0]\n",
            " [299 148 153 ...   0   0   0]], shape=(64, 40), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 64\n",
        "# 將 batch 裡的所有序列都 pad 到同樣長度\n",
        "tmp_dataset = tmp_dataset.padded_batch(BATCH_SIZE, padded_shapes=([-1], [-1]))\n",
        "ch_batch, zh_batch = next(iter(tmp_dataset))\n",
        "print(\"中文索引序列的 batch\")\n",
        "print(ch_batch)\n",
        "print('-' * 20)\n",
        "print(\"台語索引序列的 batch\")\n",
        "print(zh_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "7V5bjLq4c4Tt"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 40\n",
        "BATCH_SIZE = 128\n",
        "BUFFER_SIZE = 15000\n",
        "\n",
        "# 訓練集\n",
        "train_dataset = (train_examples  # 輸出：(中文句子, 台語句子)\n",
        "                 .map(tf_encode) # 輸出：(英文索引序列, 中文索引序列)\n",
        "                 .filter(filter_max_length) # 同上，且序列長度都不超過 40\n",
        "                 .cache() # 加快讀取數據\n",
        "                 .shuffle(BUFFER_SIZE) # 將例子洗牌確保隨機性\n",
        "                 .padded_batch(BATCH_SIZE, # 將 batch 裡的序列都 pad 到一樣長度\n",
        "                               padded_shapes=([-1], [-1]))\n",
        "                 .prefetch(tf.data.experimental.AUTOTUNE)) # 加速\n",
        "# 驗證集\n",
        "val_dataset = (val_examples\n",
        "               .map(tf_encode)\n",
        "               .filter(filter_max_length)\n",
        "               .padded_batch(BATCH_SIZE, \n",
        "                             padded_shapes=([-1], [-1])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "3MsMQIjcfM2F"
      },
      "outputs": [],
      "source": [
        "# # 因為我們數據量小可以這樣 count\n",
        "# num_examples = 0\n",
        "# for ch_indices, zh_indices in train_dataset:\n",
        "#   cond1 = len(ch_indices) <= MAX_LENGTH\n",
        "#   cond2 = len(zh_indices) <= MAX_LENGTH\n",
        "#   #assert cond1 and cond2\n",
        "#   #if cond1 and cond2:\n",
        "#   num_examples += 1\n",
        "\n",
        "# print(f\"所有序列長度都不超過 {MAX_LENGTH} 個 tokens\")\n",
        "# print(f\"訓練資料集裡總共有 {num_examples} 筆數據\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NztRWcO3c5sb",
        "outputId": "2826ef3c-bf06-41f4-c06e-19146fdac1cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "中文索引序列的 batch\n",
            "tf.Tensor(\n",
            "[[8435  739  668 ...    0    0    0]\n",
            " [8435  194 3300 ...    0    0    0]\n",
            " [8435   36 6120 ...    0    0    0]\n",
            " ...\n",
            " [8435 1414 6534 ...    0    0    0]\n",
            " [8435 2026  455 ...    0    0    0]\n",
            " [8435 1462 3843 ...    0    0    0]], shape=(128, 11), dtype=int64)\n",
            "--------------------\n",
            "台語索引序列的 batch\n",
            "tf.Tensor(\n",
            "[[299 140 153 ...   0   0   0]\n",
            " [299 159 158 ...  75   1 300]\n",
            " [299 152  98 ...   0   0   0]\n",
            " ...\n",
            " [299 153 153 ...   0   0   0]\n",
            " [299 159 158 ...   0   0   0]\n",
            " [299 160  98 ...   0   0   0]], shape=(128, 40), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "ch_batch, zh_batch = next(iter(train_dataset))\n",
        "print(\"中文索引序列的 batch\")\n",
        "print(ch_batch)\n",
        "print('-' * 20)\n",
        "print(\"台語索引序列的 batch\")\n",
        "print(zh_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPmrmUKjc7qD",
        "outputId": "f7faedb9-a51d-4853-a7a3-62f478320bcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('佇菜園種有機青菜 ', 'ti tshai hng tsing iu ki1 tshenn tshai'),\n",
            " ('反倒轉利用環保的生態防治法', 'huan to tng li iong khuan po e senn thai hong ti huat')]\n"
          ]
        }
      ],
      "source": [
        "demo_examples = [\n",
        "    (\"佇菜園種有機青菜 \", \"ti tshai hng tsing iu ki1 tshenn tshai\"),\n",
        "    (\"反倒轉利用環保的生態防治法\", \"huan to tng li iong khuan po e senn thai hong ti huat\"),\n",
        "]\n",
        "pprint(demo_examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rl7OhCtec83X",
        "outputId": "a234e310-4670-49fb-a5fb-1996d9038580"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inp: tf.Tensor(\n",
            "[[8435    5 6516  146 3858 1672 8211 8436    0    0]\n",
            " [8435  345 1760  469 1131 2044 1817 6923   97 8436]], shape=(2, 10), dtype=int64)\n",
            "\n",
            "tar: tf.Tensor(\n",
            "[[299 159 148  75 159 158 147 140 148  75 147 153 146  75 159 158 148 153\n",
            "  146  75 148 160  75 150 148  92  75 159 158 147 144 153 153  75 159 158\n",
            "  147 140 148 300   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0]\n",
            " [299 147 160 140 153  75 159 154  75 159 153 146  75 151 148  75 148 154\n",
            "  153 146  75 150 147 160 140 153  75 155 154  75 144  75 158 144 153 153\n",
            "   75 159 147 140 148  75 147 154 153 146  75 159 148  75 147 160 140 159\n",
            "  300]], shape=(2, 55), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "batch_size = 2\n",
        "demo_examples = tf.data.Dataset.from_tensor_slices((\n",
        "    [ch for ch, _ in demo_examples], [zh for _, zh in demo_examples]\n",
        "))\n",
        "\n",
        "# 將兩個句子透過之前定義的字典轉換成子詞的序列（sequence of subwords）\n",
        "# 並添加 padding token: <pad> 來確保 batch 裡的句子有一樣長度\n",
        "demo_dataset = demo_examples.map(tf_encode)\\\n",
        "  .padded_batch(batch_size, padded_shapes=([-1], [-1]))\n",
        "\n",
        "# 取出這個 demo dataset 裡唯一一個 batch\n",
        "inp, tar = next(iter(demo_dataset))\n",
        "print('inp:', inp)\n",
        "print('' * 10)\n",
        "print('tar:', tar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OwFUsL2c_Eu",
        "outputId": "8423e729-aa0c-4b6b-ebd6-06546422d433"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(2, 10, 4), dtype=float32, numpy=\n",
              " array([[[ 0.02935244,  0.03554614,  0.01736045,  0.02575929],\n",
              "         [-0.03594353,  0.01885075,  0.03922334, -0.00784503],\n",
              "         [-0.03059219,  0.01373898, -0.00424446, -0.02270319],\n",
              "         [ 0.04029178, -0.02860543,  0.04083917, -0.03974632],\n",
              "         [ 0.03491883, -0.01808844, -0.00810398, -0.00344821],\n",
              "         [ 0.02062017, -0.04103831,  0.00197386, -0.03821779],\n",
              "         [ 0.01965567,  0.04608833, -0.00050522,  0.04238245],\n",
              "         [ 0.02151975, -0.00338126, -0.00539899, -0.0355748 ],\n",
              "         [-0.02430863,  0.01005951,  0.01137512, -0.01772247],\n",
              "         [-0.02430863,  0.01005951,  0.01137512, -0.01772247]],\n",
              " \n",
              "        [[ 0.02935244,  0.03554614,  0.01736045,  0.02575929],\n",
              "         [ 0.03484343,  0.04224272,  0.03947636,  0.01727359],\n",
              "         [-0.02818116, -0.0363391 ,  0.00415504, -0.0146267 ],\n",
              "         [-0.03855926, -0.03173556,  0.04078556,  0.03262645],\n",
              "         [ 0.02185332,  0.0097766 , -0.04647985, -0.04552171],\n",
              "         [ 0.03356006,  0.01610223,  0.02188022,  0.01938898],\n",
              "         [ 0.04685703, -0.04407927,  0.00547624, -0.00190698],\n",
              "         [ 0.03725089, -0.02967271, -0.04921424,  0.01288768],\n",
              "         [-0.04117537, -0.00766627,  0.04484664, -0.0131226 ],\n",
              "         [ 0.02151975, -0.00338126, -0.00539899, -0.0355748 ]]],\n",
              "       dtype=float32)>, <tf.Tensor: shape=(2, 55, 4), dtype=float32, numpy=\n",
              " array([[[-0.0190919 , -0.00201263, -0.01303856, -0.02510204],\n",
              "         [-0.02460332,  0.00036935,  0.04674867,  0.01960564],\n",
              "         [ 0.02463751,  0.00880463, -0.00514092, -0.03603983],\n",
              "         [-0.04945021,  0.03963875, -0.04859821,  0.00969683],\n",
              "         [-0.02460332,  0.00036935,  0.04674867,  0.01960564],\n",
              "         [ 0.00856012, -0.01226419,  0.02874683, -0.04015855],\n",
              "         [-0.02816296,  0.00966698, -0.00221155,  0.0073831 ],\n",
              "         [ 0.02771181,  0.04394838,  0.01171549, -0.04838048],\n",
              "         [ 0.02463751,  0.00880463, -0.00514092, -0.03603983],\n",
              "         [-0.04945021,  0.03963875, -0.04859821,  0.00969683],\n",
              "         [-0.02816296,  0.00966698, -0.00221155,  0.0073831 ],\n",
              "         [-0.00686067,  0.04643979, -0.0413846 , -0.02162947],\n",
              "         [-0.01786237,  0.00560535, -0.04371337,  0.02780685],\n",
              "         [-0.04945021,  0.03963875, -0.04859821,  0.00969683],\n",
              "         [-0.02460332,  0.00036935,  0.04674867,  0.01960564],\n",
              "         [ 0.00856012, -0.01226419,  0.02874683, -0.04015855],\n",
              "         [ 0.02463751,  0.00880463, -0.00514092, -0.03603983],\n",
              "         [-0.00686067,  0.04643979, -0.0413846 , -0.02162947],\n",
              "         [-0.01786237,  0.00560535, -0.04371337,  0.02780685],\n",
              "         [-0.04945021,  0.03963875, -0.04859821,  0.00969683],\n",
              "         [ 0.02463751,  0.00880463, -0.00514092, -0.03603983],\n",
              "         [ 0.02972369, -0.04810737, -0.03303741,  0.04613603],\n",
              "         [-0.04945021,  0.03963875, -0.04859821,  0.00969683],\n",
              "         [ 0.04480283,  0.038434  , -0.04184365,  0.02166598],\n",
              "         [ 0.02463751,  0.00880463, -0.00514092, -0.03603983],\n",
              "         [-0.01177984, -0.03202578,  0.03309724, -0.02195791],\n",
              "         [-0.04945021,  0.03963875, -0.04859821,  0.00969683],\n",
              "         [-0.02460332,  0.00036935,  0.04674867,  0.01960564],\n",
              "         [ 0.00856012, -0.01226419,  0.02874683, -0.04015855],\n",
              "         [-0.02816296,  0.00966698, -0.00221155,  0.0073831 ],\n",
              "         [ 0.01204687, -0.04859294,  0.0436013 ,  0.03561128],\n",
              "         [-0.00686067,  0.04643979, -0.0413846 , -0.02162947],\n",
              "         [-0.00686067,  0.04643979, -0.0413846 , -0.02162947],\n",
              "         [-0.04945021,  0.03963875, -0.04859821,  0.00969683],\n",
              "         [-0.02460332,  0.00036935,  0.04674867,  0.01960564],\n",
              "         [ 0.00856012, -0.01226419,  0.02874683, -0.04015855],\n",
              "         [-0.02816296,  0.00966698, -0.00221155,  0.0073831 ],\n",
              "         [ 0.02771181,  0.04394838,  0.01171549, -0.04838048],\n",
              "         [ 0.02463751,  0.00880463, -0.00514092, -0.03603983],\n",
              "         [ 0.04444501, -0.03202839, -0.0314198 , -0.04058455],\n",
              "         [ 0.03725791,  0.04257536,  0.00082171,  0.00264676],\n",
              "         [ 0.03725791,  0.04257536,  0.00082171,  0.00264676],\n",
              "         [ 0.03725791,  0.04257536,  0.00082171,  0.00264676],\n",
              "         [ 0.03725791,  0.04257536,  0.00082171,  0.00264676],\n",
              "         [ 0.03725791,  0.04257536,  0.00082171,  0.00264676],\n",
              "         [ 0.03725791,  0.04257536,  0.00082171,  0.00264676],\n",
              "         [ 0.03725791,  0.04257536,  0.00082171,  0.00264676],\n",
              "         [ 0.03725791,  0.04257536,  0.00082171,  0.00264676],\n",
              "         [ 0.03725791,  0.04257536,  0.00082171,  0.00264676],\n",
              "         [ 0.03725791,  0.04257536,  0.00082171,  0.00264676],\n",
              "         [ 0.03725791,  0.04257536,  0.00082171,  0.00264676],\n",
              "         [ 0.03725791,  0.04257536,  0.00082171,  0.00264676],\n",
              "         [ 0.03725791,  0.04257536,  0.00082171,  0.00264676],\n",
              "         [ 0.03725791,  0.04257536,  0.00082171,  0.00264676],\n",
              "         [ 0.03725791,  0.04257536,  0.00082171,  0.00264676]],\n",
              " \n",
              "        [[-0.0190919 , -0.00201263, -0.01303856, -0.02510204],\n",
              "         [-0.02816296,  0.00966698, -0.00221155,  0.0073831 ],\n",
              "         [ 0.02972369, -0.04810737, -0.03303741,  0.04613603],\n",
              "         [ 0.02771181,  0.04394838,  0.01171549, -0.04838048],\n",
              "         [-0.00686067,  0.04643979, -0.0413846 , -0.02162947],\n",
              "         [-0.04945021,  0.03963875, -0.04859821,  0.00969683],\n",
              "         [-0.02460332,  0.00036935,  0.04674867,  0.01960564],\n",
              "         [-0.00915013, -0.00927166,  0.00793984,  0.00561764],\n",
              "         [-0.04945021,  0.03963875, -0.04859821,  0.00969683],\n",
              "         [-0.02460332,  0.00036935,  0.04674867,  0.01960564],\n",
              "         [-0.00686067,  0.04643979, -0.0413846 , -0.02162947],\n",
              "         [-0.01786237,  0.00560535, -0.04371337,  0.02780685],\n",
              "         [-0.04945021,  0.03963875, -0.04859821,  0.00969683],\n",
              "         [ 0.03892842, -0.01577774,  0.00067146,  0.04548496],\n",
              "         [ 0.02463751,  0.00880463, -0.00514092, -0.03603983],\n",
              "         [-0.04945021,  0.03963875, -0.04859821,  0.00969683],\n",
              "         [ 0.02463751,  0.00880463, -0.00514092, -0.03603983],\n",
              "         [-0.00915013, -0.00927166,  0.00793984,  0.00561764],\n",
              "         [-0.00686067,  0.04643979, -0.0413846 , -0.02162947],\n",
              "         [-0.01786237,  0.00560535, -0.04371337,  0.02780685],\n",
              "         [-0.04945021,  0.03963875, -0.04859821,  0.00969683],\n",
              "         [ 0.04480283,  0.038434  , -0.04184365,  0.02166598],\n",
              "         [-0.02816296,  0.00966698, -0.00221155,  0.0073831 ],\n",
              "         [ 0.02972369, -0.04810737, -0.03303741,  0.04613603],\n",
              "         [ 0.02771181,  0.04394838,  0.01171549, -0.04838048],\n",
              "         [-0.00686067,  0.04643979, -0.0413846 , -0.02162947],\n",
              "         [-0.04945021,  0.03963875, -0.04859821,  0.00969683],\n",
              "         [ 0.00101025,  0.00090782, -0.00990582, -0.00317892],\n",
              "         [-0.00915013, -0.00927166,  0.00793984,  0.00561764],\n",
              "         [-0.04945021,  0.03963875, -0.04859821,  0.00969683],\n",
              "         [ 0.01204687, -0.04859294,  0.0436013 ,  0.03561128],\n",
              "         [-0.04945021,  0.03963875, -0.04859821,  0.00969683],\n",
              "         [ 0.00856012, -0.01226419,  0.02874683, -0.04015855],\n",
              "         [ 0.01204687, -0.04859294,  0.0436013 ,  0.03561128],\n",
              "         [-0.00686067,  0.04643979, -0.0413846 , -0.02162947],\n",
              "         [-0.00686067,  0.04643979, -0.0413846 , -0.02162947],\n",
              "         [-0.04945021,  0.03963875, -0.04859821,  0.00969683],\n",
              "         [-0.02460332,  0.00036935,  0.04674867,  0.01960564],\n",
              "         [-0.02816296,  0.00966698, -0.00221155,  0.0073831 ],\n",
              "         [ 0.02771181,  0.04394838,  0.01171549, -0.04838048],\n",
              "         [ 0.02463751,  0.00880463, -0.00514092, -0.03603983],\n",
              "         [-0.04945021,  0.03963875, -0.04859821,  0.00969683],\n",
              "         [-0.02816296,  0.00966698, -0.00221155,  0.0073831 ],\n",
              "         [-0.00915013, -0.00927166,  0.00793984,  0.00561764],\n",
              "         [-0.00686067,  0.04643979, -0.0413846 , -0.02162947],\n",
              "         [-0.01786237,  0.00560535, -0.04371337,  0.02780685],\n",
              "         [-0.04945021,  0.03963875, -0.04859821,  0.00969683],\n",
              "         [-0.02460332,  0.00036935,  0.04674867,  0.01960564],\n",
              "         [ 0.02463751,  0.00880463, -0.00514092, -0.03603983],\n",
              "         [-0.04945021,  0.03963875, -0.04859821,  0.00969683],\n",
              "         [-0.02816296,  0.00966698, -0.00221155,  0.0073831 ],\n",
              "         [ 0.02972369, -0.04810737, -0.03303741,  0.04613603],\n",
              "         [ 0.02771181,  0.04394838,  0.01171549, -0.04838048],\n",
              "         [-0.02460332,  0.00036935,  0.04674867,  0.01960564],\n",
              "         [ 0.04444501, -0.03202839, -0.0314198 , -0.04058455]]],\n",
              "       dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ],
      "source": [
        "# + 2 是因為我們額外加了 <start> 以及 <end> tokens\n",
        "vocab_size_ch = subword_encoder_ch.vocab_size + 2\n",
        "vocab_size_zh = subword_encoder_zh.vocab_size + 2\n",
        "\n",
        "# 為了方便 demo, 將詞彙轉換到一個 4 維的詞嵌入空間\n",
        "d_model = 4\n",
        "embedding_layer_ch = tf.keras.layers.Embedding(vocab_size_ch, d_model)\n",
        "embedding_layer_zh = tf.keras.layers.Embedding(vocab_size_zh, d_model)\n",
        "\n",
        "emb_inp = embedding_layer_ch(inp)\n",
        "emb_tar = embedding_layer_zh(tar)\n",
        "emb_inp, emb_tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2VXWn5Tc_HA",
        "outputId": "16d3f985-5a08-465f-f9de-04e2569df402"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tar[0]: tf.Tensor([0 0 0], shape=(3,), dtype=int64)\n",
            "--------------------\n",
            "emb_tar[0]: tf.Tensor(\n",
            "[[0.03725791 0.04257536 0.00082171 0.00264676]\n",
            " [0.03725791 0.04257536 0.00082171 0.00264676]\n",
            " [0.03725791 0.04257536 0.00082171 0.00264676]], shape=(3, 4), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "print(\"tar[0]:\", tar[0][-3:])\n",
        "print(\"-\" * 20)\n",
        "print(\"emb_tar[0]:\", emb_tar[0][-3:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUIVXr1jdEmx",
        "outputId": "dd232870-a9dd-46e7-9e77-c128dd62836d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 1, 1, 10), dtype=float32, numpy=\n",
              "array([[[[0., 0., 0., 0., 0., 0., 0., 0., 1., 1.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ],
      "source": [
        "def create_padding_mask(seq):\n",
        "  # padding mask 的工作就是把索引序列中為 0 的位置設為 1\n",
        "  mask = tf.cast(tf.equal(seq, 0), tf.float32)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :] #　broadcasting\n",
        "\n",
        "inp_mask = create_padding_mask(inp)\n",
        "inp_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVtWVr9RdGKp",
        "outputId": "68d980f5-e154-4702-a3e7-4ed3f8b2e661"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inp: tf.Tensor(\n",
            "[[8435    5 6516  146 3858 1672 8211 8436    0    0]\n",
            " [8435  345 1760  469 1131 2044 1817 6923   97 8436]], shape=(2, 10), dtype=int64)\n",
            "--------------------\n",
            "tf.squeeze(inp_mask): tf.Tensor(\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(2, 10), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "print(\"inp:\", inp)\n",
        "print(\"-\" * 20)\n",
        "print(\"tf.squeeze(inp_mask):\", tf.squeeze(inp_mask))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6O26a_umdJpG",
        "outputId": "de2952c9-2715-4c8f-c53f-d154078a6b62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 10, 4), dtype=float32, numpy=\n",
              "array([[[1., 0., 0., 0.],\n",
              "        [0., 1., 0., 1.],\n",
              "        [0., 0., 0., 1.],\n",
              "        [1., 0., 1., 0.],\n",
              "        [1., 0., 1., 0.],\n",
              "        [0., 1., 0., 1.],\n",
              "        [0., 0., 1., 0.],\n",
              "        [0., 1., 0., 1.],\n",
              "        [1., 0., 1., 1.],\n",
              "        [1., 0., 1., 0.]],\n",
              "\n",
              "       [[1., 0., 0., 0.],\n",
              "        [1., 0., 1., 0.],\n",
              "        [0., 1., 0., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [1., 1., 0., 0.],\n",
              "        [0., 0., 1., 0.]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ],
      "source": [
        "# 設定一個 seed 確保我們每次都拿到一樣的隨機結果\n",
        "tf.random.set_seed(9527)\n",
        "\n",
        "# 自注意力機制：查詢 `q` 跟鍵值 `k` 都是 `emb_inp`\n",
        "q = emb_inp\n",
        "k = emb_inp\n",
        "# 簡單產生一個跟 `emb_inp` 同樣 shape 的 binary vector\n",
        "v = tf.cast(tf.math.greater(tf.random.uniform(shape=emb_inp.shape), 0.5), tf.float32)\n",
        "v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "ak2Kq-99dMOD"
      },
      "outputs": [],
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  \"\"\"Calculate the attention weights.\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "  The mask has different shapes depending on its type(padding or look ahead) \n",
        "  but it must be broadcastable for addition.\n",
        "  \n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable \n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "    \n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "  \"\"\"\n",
        "  # 將 `q`、 `k` 做點積再 scale\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "  \n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)  # 取得 seq_k 的序列長度\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)  # scale by sqrt(dk)\n",
        "\n",
        "  # 將遮罩「加」到被丟入 softmax 前的 logits\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "  # 取 softmax 是為了得到總和為 1 的比例之後對 `v` 做加權平均\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "  \n",
        "  # 以注意權重對 v 做加權平均（weighted average）\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AU-BCxLedN_Y",
        "outputId": "369656d1-59fd-4b4b-bfe4-cad38b8c8404"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output: tf.Tensor(\n",
            "[[[0.50004596 0.29986122 0.5000564  0.49975815]\n",
            "  [0.49997276 0.30000782 0.49995857 0.50011927]\n",
            "  [0.49993533 0.30004013 0.4999423  0.5001729 ]\n",
            "  [0.5001129  0.3001398  0.5000088  0.49999368]\n",
            "  [0.50005513 0.3000251  0.500033   0.49990618]\n",
            "  [0.50005054 0.3001603  0.49998552 0.50009394]\n",
            "  [0.50000966 0.299802   0.5000602  0.49973613]\n",
            "  [0.50002104 0.30007935 0.4999841  0.5000414 ]\n",
            "  [0.49996468 0.30003625 0.49995688 0.5001308 ]\n",
            "  [0.49996468 0.30003625 0.49995688 0.5001308 ]]\n",
            "\n",
            " [[0.40019196 0.29974788 0.40018633 0.19981438]\n",
            "  [0.4002926  0.29976085 0.40026194 0.19979583]\n",
            "  [0.39995956 0.3003224  0.3999043  0.20022568]\n",
            "  [0.4003634  0.30052078 0.40011808 0.20035872]\n",
            "  [0.39955193 0.29964304 0.3997895  0.19976026]\n",
            "  [0.40012768 0.29979062 0.4001497  0.19985297]\n",
            "  [0.3997506  0.29981714 0.39993092 0.19992352]\n",
            "  [0.3995597  0.29966053 0.39980054 0.19985557]\n",
            "  [0.40031877 0.30046675 0.40010303 0.20026399]\n",
            "  [0.39977917 0.29982784 0.39991736 0.19987161]]], shape=(2, 10, 4), dtype=float32)\n",
            "--------------------\n",
            "attention_weights: tf.Tensor(\n",
            "[[[0.10014514 0.09999523 0.09993715 0.09998308 0.09999816 0.09990039\n",
            "   0.10015556 0.0999656  0.09995979 0.09995979]\n",
            "  [0.09998492 0.1001427  0.10004875 0.09997654 0.09988595 0.09992338\n",
            "   0.09997074 0.09994175 0.10006268 0.10006268]\n",
            "  [0.09994064 0.10006255 0.10007695 0.0999492  0.09993383 0.09997725\n",
            "   0.09994762 0.10000031 0.10005583 0.10005583]\n",
            "  [0.09994433 0.09994809 0.09990698 0.10023651 0.1000383  0.10013207\n",
            "   0.09984031 0.10005965 0.09994687 0.09994687]\n",
            "  [0.1000048  0.09990287 0.09993698 0.10008373 0.10007841 0.10007611\n",
            "   0.09998271 0.10004614 0.09994409 0.09994409]\n",
            "  [0.09989044 0.09992371 0.09996381 0.10016091 0.10005949 0.10015938\n",
            "   0.09982537 0.10007717 0.09996986 0.09996986]\n",
            "  [0.10017461 0.10000005 0.09996314 0.09989802 0.09999508 0.09985431\n",
            "   0.10022515 0.09994766 0.099971   0.099971  ]\n",
            "  [0.09995267 0.09993911 0.09998388 0.10008548 0.10002653 0.10007419\n",
            "   0.09991572 0.10006607 0.09997819 0.09997819]\n",
            "  [0.09995723 0.10007042 0.10004977 0.09998305 0.09993489 0.09997725\n",
            "   0.09994943 0.09998856 0.10004476 0.10004476]\n",
            "  [0.09995723 0.10007042 0.10004977 0.09998305 0.09993489 0.09997725\n",
            "   0.09994943 0.09998856 0.10004476 0.10004476]]\n",
            "\n",
            " [[0.10014012 0.10016838 0.09986442 0.09994996 0.09993601 0.10010741\n",
            "   0.09997824 0.09996133 0.09993351 0.09996059]\n",
            "  [0.1001586  0.10021875 0.09984559 0.09995024 0.09990346 0.10012824\n",
            "   0.09997344 0.09989202 0.09996501 0.09996472]\n",
            "  [0.09988472 0.09987562 0.1001232  0.10010248 0.09998091 0.09991968\n",
            "   0.10002243 0.0999876  0.10009673 0.10000654]\n",
            "  [0.09996476 0.0999748  0.10009697 0.10026176 0.09977388 0.09998631\n",
            "   0.09998798 0.0998963  0.10016204 0.0998952 ]\n",
            "  [0.09995629 0.09993349 0.09998089 0.09977937 0.1002464  0.09995538\n",
            "   0.10002708 0.10011712 0.09988279 0.10012126]\n",
            "  [0.10009843 0.10012904 0.09989043 0.09996255 0.09992613 0.10008859\n",
            "   0.10002383 0.09997382 0.09993764 0.09996954]\n",
            "  [0.09995235 0.09995732 0.09997622 0.0999473  0.09998088 0.1000069\n",
            "   0.10016837 0.10009763 0.09989363 0.1000194 ]\n",
            "  [0.09996472 0.09990515 0.09997067 0.09988489 0.10010019 0.09998617\n",
            "   0.10012694 0.10023198 0.09980496 0.10002436]\n",
            "  [0.09995366 0.09999494 0.10009658 0.10016741 0.09988265 0.09996676\n",
            "   0.09993965 0.09982171 0.10020276 0.0999739 ]\n",
            "  [0.09996308 0.09997696 0.09998871 0.0998829  0.10010343 0.099981\n",
            "   0.1000478  0.10002346 0.09995624 0.10007649]]], shape=(2, 10, 10), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "mask = None\n",
        "output, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
        "print(\"output:\", output)\n",
        "print(\"-\" * 20)\n",
        "print(\"attention_weights:\", attention_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "MjEBgSzzdRVV"
      },
      "outputs": [],
      "source": [
        "# ...\n",
        "\n",
        "# # 將 `q`、 `k` 做點積再 scale\n",
        "# scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "# # 將遮罩「加」到被丟入 softmax 前的 logits\n",
        "# if mask is not None:\n",
        "#   scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "# # 取 softmax 是為了得到總和為 1 的比例做加權平均\n",
        "# attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
        "\n",
        "# ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "rQnvM_4udTb1"
      },
      "outputs": [],
      "source": [
        "# ...\n",
        "\n",
        "# if mask is not None:\n",
        "#   scaled_attention_logits += (mask * -1e9) # 是 -1e9 不是 1e-9\n",
        "\n",
        "# attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
        "\n",
        "# ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayfB3lCTdUwE",
        "outputId": "6c7ac020-6718-4e97-f00e-c55f85aae8c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inp: tf.Tensor(\n",
            "[[8435    5 6516  146 3858 1672 8211 8436    0    0]\n",
            " [8435  345 1760  469 1131 2044 1817 6923   97 8436]], shape=(2, 10), dtype=int64)\n",
            "--------------------\n",
            "inp_mask: tf.Tensor(\n",
            "[[[[0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]]]\n",
            "\n",
            "\n",
            " [[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 1, 10), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "def create_padding_mask(seq):\n",
        "  # padding mask 的工作就是把索引序列中為 0 的位置設為 1\n",
        "  mask = tf.cast(tf.equal(seq, 0), tf.float32)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :] #　broadcasting\n",
        "\n",
        "print(\"inp:\", inp)\n",
        "inp_mask = create_padding_mask(inp)\n",
        "print(\"-\" * 20)\n",
        "print(\"inp_mask:\", inp_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5TmeNnedWOc",
        "outputId": "61de5e3a-def5-4f64-ba31-d2dabd412b5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention_weights: tf.Tensor(\n",
            "[[[0.12516886 0.12498149 0.12490889 0.12496631 0.12498515 0.12486296\n",
            "   0.12518188 0.12494446 0.         0.        ]\n",
            "  [0.12500073 0.12519798 0.12508053 0.12499025 0.12487699 0.12492379\n",
            "   0.12498299 0.12494676 0.         0.        ]\n",
            "  [0.12494321 0.12509562 0.12511364 0.12495393 0.12493471 0.124989\n",
            "   0.12495195 0.12501782 0.         0.        ]\n",
            "  [0.12491383 0.12491854 0.12486715 0.12527901 0.12503128 0.12514848\n",
            "   0.12478383 0.12505795 0.         0.        ]\n",
            "  [0.12498853 0.12486114 0.12490378 0.12508719 0.12508054 0.12507766\n",
            "   0.12496092 0.1250402  0.         0.        ]\n",
            "  [0.12485363 0.12489522 0.12494532 0.12519169 0.12506492 0.12518978\n",
            "   0.1247723  0.12508701 0.         0.        ]\n",
            "  [0.12520918 0.124991   0.12494487 0.12486348 0.12498479 0.12480885\n",
            "   0.12527236 0.12492553 0.         0.        ]\n",
            "  [0.12493402 0.12491707 0.12497303 0.12510003 0.12502636 0.1250859\n",
            "   0.12488784 0.12507576 0.         0.        ]\n",
            "  [0.12496051 0.12510201 0.1250762  0.1249928  0.12493258 0.12498554\n",
            "   0.12495075 0.12499969 0.         0.        ]\n",
            "  [0.12496051 0.12510201 0.1250762  0.1249928  0.12493258 0.12498554\n",
            "   0.12495075 0.12499969 0.         0.        ]]\n",
            "\n",
            " [[0.10014012 0.10016838 0.09986442 0.09994996 0.09993601 0.10010741\n",
            "   0.09997824 0.09996133 0.09993351 0.09996059]\n",
            "  [0.1001586  0.10021875 0.09984559 0.09995024 0.09990346 0.10012824\n",
            "   0.09997344 0.09989202 0.09996501 0.09996472]\n",
            "  [0.09988472 0.09987562 0.1001232  0.10010248 0.09998091 0.09991968\n",
            "   0.10002243 0.0999876  0.10009673 0.10000654]\n",
            "  [0.09996476 0.0999748  0.10009697 0.10026176 0.09977388 0.09998631\n",
            "   0.09998798 0.0998963  0.10016204 0.0998952 ]\n",
            "  [0.09995629 0.09993349 0.09998089 0.09977937 0.1002464  0.09995538\n",
            "   0.10002708 0.10011712 0.09988279 0.10012126]\n",
            "  [0.10009843 0.10012904 0.09989043 0.09996255 0.09992613 0.10008859\n",
            "   0.10002383 0.09997382 0.09993764 0.09996954]\n",
            "  [0.09995235 0.09995732 0.09997622 0.0999473  0.09998088 0.1000069\n",
            "   0.10016837 0.10009763 0.09989363 0.1000194 ]\n",
            "  [0.09996472 0.09990515 0.09997067 0.09988489 0.10010019 0.09998617\n",
            "   0.10012694 0.10023198 0.09980496 0.10002436]\n",
            "  [0.09995366 0.09999494 0.10009658 0.10016741 0.09988265 0.09996676\n",
            "   0.09993965 0.09982171 0.10020276 0.0999739 ]\n",
            "  [0.09996308 0.09997696 0.09998871 0.0998829  0.10010343 0.099981\n",
            "   0.1000478  0.10002346 0.09995624 0.10007649]]], shape=(2, 10, 10), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# 這次讓我們將 padding mask 放入注意函式並觀察\n",
        "# 注意權重的變化\n",
        "mask = tf.squeeze(inp_mask, axis=1) # (batch_size, 1, seq_len_q)\n",
        "_, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
        "print(\"attention_weights:\", attention_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pt0ZNYodXm7",
        "outputId": "2d17670f-3fab-4c45-8457-10109a4be7d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 10, 2), dtype=float32, numpy=\n",
              "array([[[0.        , 0.        ],\n",
              "        [0.        , 0.        ],\n",
              "        [0.        , 0.        ],\n",
              "        [0.        , 0.        ],\n",
              "        [0.        , 0.        ],\n",
              "        [0.        , 0.        ],\n",
              "        [0.        , 0.        ],\n",
              "        [0.        , 0.        ],\n",
              "        [0.        , 0.        ],\n",
              "        [0.        , 0.        ]],\n",
              "\n",
              "       [[0.09993351, 0.09996059],\n",
              "        [0.09996501, 0.09996472],\n",
              "        [0.10009673, 0.10000654],\n",
              "        [0.10016204, 0.0998952 ],\n",
              "        [0.09988279, 0.10012126],\n",
              "        [0.09993764, 0.09996954],\n",
              "        [0.09989363, 0.1000194 ],\n",
              "        [0.09980496, 0.10002436],\n",
              "        [0.10020276, 0.0999739 ],\n",
              "        [0.09995624, 0.10007649]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ],
      "source": [
        "# 事實上也不完全是上句話的翻譯，\n",
        "# 因為我們在第一個維度還是把兩個句子都拿出來方便你比較\n",
        "attention_weights[:, :, -2:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "zWVknoWUdZkd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMs3-H39dZly",
        "outputId": "ad19d700-aebb-4484-e0d9-712a29edec59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emb_tar: tf.Tensor(\n",
            "[[[-0.0190919  -0.00201263 -0.01303856 -0.02510204]\n",
            "  [-0.02460332  0.00036935  0.04674867  0.01960564]\n",
            "  [ 0.02463751  0.00880463 -0.00514092 -0.03603983]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [-0.02460332  0.00036935  0.04674867  0.01960564]\n",
            "  [ 0.00856012 -0.01226419  0.02874683 -0.04015855]\n",
            "  [-0.02816296  0.00966698 -0.00221155  0.0073831 ]\n",
            "  [ 0.02771181  0.04394838  0.01171549 -0.04838048]\n",
            "  [ 0.02463751  0.00880463 -0.00514092 -0.03603983]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [-0.02816296  0.00966698 -0.00221155  0.0073831 ]\n",
            "  [-0.00686067  0.04643979 -0.0413846  -0.02162947]\n",
            "  [-0.01786237  0.00560535 -0.04371337  0.02780685]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [-0.02460332  0.00036935  0.04674867  0.01960564]\n",
            "  [ 0.00856012 -0.01226419  0.02874683 -0.04015855]\n",
            "  [ 0.02463751  0.00880463 -0.00514092 -0.03603983]\n",
            "  [-0.00686067  0.04643979 -0.0413846  -0.02162947]\n",
            "  [-0.01786237  0.00560535 -0.04371337  0.02780685]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [ 0.02463751  0.00880463 -0.00514092 -0.03603983]\n",
            "  [ 0.02972369 -0.04810737 -0.03303741  0.04613603]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [ 0.04480283  0.038434   -0.04184365  0.02166598]\n",
            "  [ 0.02463751  0.00880463 -0.00514092 -0.03603983]\n",
            "  [-0.01177984 -0.03202578  0.03309724 -0.02195791]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [-0.02460332  0.00036935  0.04674867  0.01960564]\n",
            "  [ 0.00856012 -0.01226419  0.02874683 -0.04015855]\n",
            "  [-0.02816296  0.00966698 -0.00221155  0.0073831 ]\n",
            "  [ 0.01204687 -0.04859294  0.0436013   0.03561128]\n",
            "  [-0.00686067  0.04643979 -0.0413846  -0.02162947]\n",
            "  [-0.00686067  0.04643979 -0.0413846  -0.02162947]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [-0.02460332  0.00036935  0.04674867  0.01960564]\n",
            "  [ 0.00856012 -0.01226419  0.02874683 -0.04015855]\n",
            "  [-0.02816296  0.00966698 -0.00221155  0.0073831 ]\n",
            "  [ 0.02771181  0.04394838  0.01171549 -0.04838048]\n",
            "  [ 0.02463751  0.00880463 -0.00514092 -0.03603983]\n",
            "  [ 0.04444501 -0.03202839 -0.0314198  -0.04058455]\n",
            "  [ 0.03725791  0.04257536  0.00082171  0.00264676]\n",
            "  [ 0.03725791  0.04257536  0.00082171  0.00264676]\n",
            "  [ 0.03725791  0.04257536  0.00082171  0.00264676]\n",
            "  [ 0.03725791  0.04257536  0.00082171  0.00264676]\n",
            "  [ 0.03725791  0.04257536  0.00082171  0.00264676]\n",
            "  [ 0.03725791  0.04257536  0.00082171  0.00264676]\n",
            "  [ 0.03725791  0.04257536  0.00082171  0.00264676]\n",
            "  [ 0.03725791  0.04257536  0.00082171  0.00264676]\n",
            "  [ 0.03725791  0.04257536  0.00082171  0.00264676]\n",
            "  [ 0.03725791  0.04257536  0.00082171  0.00264676]\n",
            "  [ 0.03725791  0.04257536  0.00082171  0.00264676]\n",
            "  [ 0.03725791  0.04257536  0.00082171  0.00264676]\n",
            "  [ 0.03725791  0.04257536  0.00082171  0.00264676]\n",
            "  [ 0.03725791  0.04257536  0.00082171  0.00264676]\n",
            "  [ 0.03725791  0.04257536  0.00082171  0.00264676]]\n",
            "\n",
            " [[-0.0190919  -0.00201263 -0.01303856 -0.02510204]\n",
            "  [-0.02816296  0.00966698 -0.00221155  0.0073831 ]\n",
            "  [ 0.02972369 -0.04810737 -0.03303741  0.04613603]\n",
            "  [ 0.02771181  0.04394838  0.01171549 -0.04838048]\n",
            "  [-0.00686067  0.04643979 -0.0413846  -0.02162947]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [-0.02460332  0.00036935  0.04674867  0.01960564]\n",
            "  [-0.00915013 -0.00927166  0.00793984  0.00561764]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [-0.02460332  0.00036935  0.04674867  0.01960564]\n",
            "  [-0.00686067  0.04643979 -0.0413846  -0.02162947]\n",
            "  [-0.01786237  0.00560535 -0.04371337  0.02780685]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [ 0.03892842 -0.01577774  0.00067146  0.04548496]\n",
            "  [ 0.02463751  0.00880463 -0.00514092 -0.03603983]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [ 0.02463751  0.00880463 -0.00514092 -0.03603983]\n",
            "  [-0.00915013 -0.00927166  0.00793984  0.00561764]\n",
            "  [-0.00686067  0.04643979 -0.0413846  -0.02162947]\n",
            "  [-0.01786237  0.00560535 -0.04371337  0.02780685]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [ 0.04480283  0.038434   -0.04184365  0.02166598]\n",
            "  [-0.02816296  0.00966698 -0.00221155  0.0073831 ]\n",
            "  [ 0.02972369 -0.04810737 -0.03303741  0.04613603]\n",
            "  [ 0.02771181  0.04394838  0.01171549 -0.04838048]\n",
            "  [-0.00686067  0.04643979 -0.0413846  -0.02162947]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [ 0.00101025  0.00090782 -0.00990582 -0.00317892]\n",
            "  [-0.00915013 -0.00927166  0.00793984  0.00561764]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [ 0.01204687 -0.04859294  0.0436013   0.03561128]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [ 0.00856012 -0.01226419  0.02874683 -0.04015855]\n",
            "  [ 0.01204687 -0.04859294  0.0436013   0.03561128]\n",
            "  [-0.00686067  0.04643979 -0.0413846  -0.02162947]\n",
            "  [-0.00686067  0.04643979 -0.0413846  -0.02162947]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [-0.02460332  0.00036935  0.04674867  0.01960564]\n",
            "  [-0.02816296  0.00966698 -0.00221155  0.0073831 ]\n",
            "  [ 0.02771181  0.04394838  0.01171549 -0.04838048]\n",
            "  [ 0.02463751  0.00880463 -0.00514092 -0.03603983]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [-0.02816296  0.00966698 -0.00221155  0.0073831 ]\n",
            "  [-0.00915013 -0.00927166  0.00793984  0.00561764]\n",
            "  [-0.00686067  0.04643979 -0.0413846  -0.02162947]\n",
            "  [-0.01786237  0.00560535 -0.04371337  0.02780685]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [-0.02460332  0.00036935  0.04674867  0.01960564]\n",
            "  [ 0.02463751  0.00880463 -0.00514092 -0.03603983]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [-0.02816296  0.00966698 -0.00221155  0.0073831 ]\n",
            "  [ 0.02972369 -0.04810737 -0.03303741  0.04613603]\n",
            "  [ 0.02771181  0.04394838  0.01171549 -0.04838048]\n",
            "  [-0.02460332  0.00036935  0.04674867  0.01960564]\n",
            "  [ 0.04444501 -0.03202839 -0.0314198  -0.04058455]]], shape=(2, 55, 4), dtype=float32)\n",
            "--------------------\n",
            "look_ahead_mask tf.Tensor(\n",
            "[[0. 1. 1. ... 1. 1. 1.]\n",
            " [0. 0. 1. ... 1. 1. 1.]\n",
            " [0. 0. 0. ... 1. 1. 1.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 1. 1.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 0.]], shape=(55, 55), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# 建立一個 2 維矩陣，維度為 (size, size)，\n",
        "# 其遮罩為一個右上角的三角形\n",
        "def create_look_ahead_mask(size):\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "  return mask  # (seq_len, seq_len)\n",
        "\n",
        "seq_len = emb_tar.shape[1] # 注意這次我們用中文的詞嵌入張量 `emb_tar`\n",
        "look_ahead_mask = create_look_ahead_mask(seq_len)\n",
        "print(\"emb_tar:\", emb_tar)\n",
        "print(\"-\" * 20)\n",
        "print(\"look_ahead_mask\", look_ahead_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vjZSIxsdbSQ",
        "outputId": "39f4e437-2d55-4624-b806-b65e383d203c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention_weights: tf.Tensor(\n",
            "[[[0.99999994 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.499524   0.500476   0.         ... 0.         0.         0.        ]\n",
            "  [0.33336142 0.33302265 0.3336159  ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.01885082 0.01885142 0.01887032 ... 0.01888934 0.         0.        ]\n",
            "  [0.01850134 0.01850193 0.01852047 ... 0.01853915 0.01853915 0.        ]\n",
            "  [0.01816459 0.01816516 0.01818337 ... 0.0182017  0.0182017  0.0182017 ]]\n",
            "\n",
            " [[0.99999994 0.         0.         ... 0.         0.         0.        ]\n",
            "  [0.49992695 0.500073   0.         ... 0.         0.         0.        ]\n",
            "  [0.3328928  0.33294433 0.33416286 ... 0.         0.         0.        ]\n",
            "  ...\n",
            "  [0.0188708  0.01885964 0.01882976 ... 0.01891551 0.         0.        ]\n",
            "  [0.018516   0.01852869 0.018509   ... 0.01851198 0.01855129 0.        ]\n",
            "  [0.01819193 0.01816979 0.01820452 ... 0.01819898 0.01815546 0.01823739]]], shape=(2, 55, 55), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# 讓我們用目標語言（台語）的 batch\n",
        "# 來模擬 Decoder 處理的情況\n",
        "temp_q = temp_k = emb_tar\n",
        "temp_v = tf.cast(tf.math.greater(\n",
        "    tf.random.uniform(shape=emb_tar.shape), 0.5), tf.float32)\n",
        "\n",
        "# 將 look_ahead_mask 放入注意函式\n",
        "_, attention_weights = scaled_dot_product_attention(\n",
        "    temp_q, temp_k, temp_v, look_ahead_mask)\n",
        "\n",
        "print(\"attention_weights:\", attention_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JEX7mWmddBv",
        "outputId": "d6d73bd3-e612-4176-a680-31beee0e413f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 55), dtype=float32, numpy=\n",
              "array([[0.99999994, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.99999994, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ],
      "source": [
        "attention_weights[:, 0, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtZ0YjMYdedG",
        "outputId": "7edb76f4-6ebc-4e11-b88c-b4ac823ebb82"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 55), dtype=float32, numpy=\n",
              "array([[0.499524  , 0.500476  , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.49992695, 0.500073  , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ],
      "source": [
        "attention_weights[:, 1, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "IgtH-HhqdiB7"
      },
      "outputs": [],
      "source": [
        "#num_heads * depth = d_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lHuo-DQdjaZ",
        "outputId": "70aedc6c-6f81-4723-9061-9ec43fb0ef16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: tf.Tensor(\n",
            "[[[ 0.02935244  0.03554614  0.01736045  0.02575929]\n",
            "  [-0.03594353  0.01885075  0.03922334 -0.00784503]\n",
            "  [-0.03059219  0.01373898 -0.00424446 -0.02270319]\n",
            "  [ 0.04029178 -0.02860543  0.04083917 -0.03974632]\n",
            "  [ 0.03491883 -0.01808844 -0.00810398 -0.00344821]\n",
            "  [ 0.02062017 -0.04103831  0.00197386 -0.03821779]\n",
            "  [ 0.01965567  0.04608833 -0.00050522  0.04238245]\n",
            "  [ 0.02151975 -0.00338126 -0.00539899 -0.0355748 ]\n",
            "  [-0.02430863  0.01005951  0.01137512 -0.01772247]\n",
            "  [-0.02430863  0.01005951  0.01137512 -0.01772247]]\n",
            "\n",
            " [[ 0.02935244  0.03554614  0.01736045  0.02575929]\n",
            "  [ 0.03484343  0.04224272  0.03947636  0.01727359]\n",
            "  [-0.02818116 -0.0363391   0.00415504 -0.0146267 ]\n",
            "  [-0.03855926 -0.03173556  0.04078556  0.03262645]\n",
            "  [ 0.02185332  0.0097766  -0.04647985 -0.04552171]\n",
            "  [ 0.03356006  0.01610223  0.02188022  0.01938898]\n",
            "  [ 0.04685703 -0.04407927  0.00547624 -0.00190698]\n",
            "  [ 0.03725089 -0.02967271 -0.04921424  0.01288768]\n",
            "  [-0.04117537 -0.00766627  0.04484664 -0.0131226 ]\n",
            "  [ 0.02151975 -0.00338126 -0.00539899 -0.0355748 ]]], shape=(2, 10, 4), dtype=float32)\n",
            "output: tf.Tensor(\n",
            "[[[[ 0.02935244  0.03554614]\n",
            "   [-0.03594353  0.01885075]\n",
            "   [-0.03059219  0.01373898]\n",
            "   [ 0.04029178 -0.02860543]\n",
            "   [ 0.03491883 -0.01808844]\n",
            "   [ 0.02062017 -0.04103831]\n",
            "   [ 0.01965567  0.04608833]\n",
            "   [ 0.02151975 -0.00338126]\n",
            "   [-0.02430863  0.01005951]\n",
            "   [-0.02430863  0.01005951]]\n",
            "\n",
            "  [[ 0.01736045  0.02575929]\n",
            "   [ 0.03922334 -0.00784503]\n",
            "   [-0.00424446 -0.02270319]\n",
            "   [ 0.04083917 -0.03974632]\n",
            "   [-0.00810398 -0.00344821]\n",
            "   [ 0.00197386 -0.03821779]\n",
            "   [-0.00050522  0.04238245]\n",
            "   [-0.00539899 -0.0355748 ]\n",
            "   [ 0.01137512 -0.01772247]\n",
            "   [ 0.01137512 -0.01772247]]]\n",
            "\n",
            "\n",
            " [[[ 0.02935244  0.03554614]\n",
            "   [ 0.03484343  0.04224272]\n",
            "   [-0.02818116 -0.0363391 ]\n",
            "   [-0.03855926 -0.03173556]\n",
            "   [ 0.02185332  0.0097766 ]\n",
            "   [ 0.03356006  0.01610223]\n",
            "   [ 0.04685703 -0.04407927]\n",
            "   [ 0.03725089 -0.02967271]\n",
            "   [-0.04117537 -0.00766627]\n",
            "   [ 0.02151975 -0.00338126]]\n",
            "\n",
            "  [[ 0.01736045  0.02575929]\n",
            "   [ 0.03947636  0.01727359]\n",
            "   [ 0.00415504 -0.0146267 ]\n",
            "   [ 0.04078556  0.03262645]\n",
            "   [-0.04647985 -0.04552171]\n",
            "   [ 0.02188022  0.01938898]\n",
            "   [ 0.00547624 -0.00190698]\n",
            "   [-0.04921424  0.01288768]\n",
            "   [ 0.04484664 -0.0131226 ]\n",
            "   [-0.00539899 -0.0355748 ]]]], shape=(2, 2, 10, 2), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "def split_heads(x, d_model, num_heads):\n",
        "  # x.shape: (batch_size, seq_len, d_model)\n",
        "  batch_size = tf.shape(x)[0]\n",
        "  \n",
        "  # 我們要確保維度 `d_model` 可以被平分成 `num_heads` 個 `depth` 維度\n",
        "  assert d_model % num_heads == 0\n",
        "  depth = d_model // num_heads  # 這是分成多頭以後每個向量的維度 \n",
        "  \n",
        "  # 將最後一個 d_model 維度分成 num_heads 個 depth 維度。\n",
        "  # 最後一個維度變成兩個維度，張量 x 從 3 維到 4 維\n",
        "  # (batch_size, seq_len, num_heads, depth)\n",
        "  reshaped_x = tf.reshape(x, shape=(batch_size, -1, num_heads, depth))\n",
        "  \n",
        "  # 將 head 的維度拉前使得最後兩個維度為子詞以及其對應的 depth 向量\n",
        "  # (batch_size, num_heads, seq_len, depth)\n",
        "  output = tf.transpose(reshaped_x, perm=[0, 2, 1, 3])\n",
        "  \n",
        "  return output\n",
        "\n",
        "# 我們的 `emb_inp` 裡頭的子詞本來就是 4 維的詞嵌入向量\n",
        "d_model = 4\n",
        "# 將 4 維詞嵌入向量分為 2 個 head 的 2 維矩陣\n",
        "num_heads = 2\n",
        "x = emb_inp\n",
        "\n",
        "output = split_heads(x, d_model, num_heads)  \n",
        "print(\"x:\", x)\n",
        "print(\"output:\", output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "BJtZcdHldork"
      },
      "outputs": [],
      "source": [
        "# 實作一個執行多頭注意力機制的 keras layer\n",
        "# 在初始的時候指定輸出維度 `d_model` & `num_heads，\n",
        "# 在呼叫的時候輸入 `v`, `k`, `q` 以及 `mask`\n",
        "# 輸出跟 scaled_dot_product_attention 函式一樣有兩個：\n",
        "# output.shape            == (batch_size, seq_len_q, d_model)\n",
        "# attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  # 在初始的時候建立一些必要參數\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads # 指定要將 `d_model` 拆成幾個 heads\n",
        "    self.d_model = d_model # 在 split_heads 之前的基底維度\n",
        "    \n",
        "    assert d_model % self.num_heads == 0  # 前面看過，要確保可以平分\n",
        "    \n",
        "    self.depth = d_model // self.num_heads  # 每個 head 裡子詞的新的 repr. 維度\n",
        "    \n",
        "    self.wq = tf.keras.layers.Dense(d_model)  # 分別給 q, k, v 的 3 個線性轉換 \n",
        "    self.wk = tf.keras.layers.Dense(d_model)  # 注意我們並沒有指定 activation func\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "    \n",
        "    self.dense = tf.keras.layers.Dense(d_model)  # 多 heads 串接後通過的線性轉換\n",
        "  \n",
        "  # 這跟我們前面看過的函式有 87% 相似\n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "  \n",
        "  # multi-head attention 的實際執行流程，注意參數順序（這邊跟論文以及 TensorFlow 官方教學一致）\n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "    \n",
        "    # 將輸入的 q, k, v 都各自做一次線性轉換到 `d_model` 維空間\n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "    \n",
        "    # 前面看過的，將最後一個 `d_model` 維度分成 `num_heads` 個 `depth` 維度\n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "    \n",
        "    # 利用 broadcasting 讓每個句子的每個 head 的 qi, ki, vi 都各自進行注意力機制\n",
        "    # 輸出會多一個 head 維度\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "    \n",
        "    # 跟我們在 `split_heads` 函式做的事情剛好相反，先做 transpose 再做 reshape\n",
        "    # 將 `num_heads` 個 `depth` 維度串接回原來的 `d_model` 維度\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "    # (batch_size, seq_len_q, num_heads, depth)\n",
        "    concat_attention = tf.reshape(scaled_attention, \n",
        "                                  (batch_size, -1, self.d_model)) \n",
        "    # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    # 通過最後一個線性轉換\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "        \n",
        "    return output, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFzeszu8dqwY",
        "outputId": "2e450446-f894-454d-d001-f50177db6e4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "d_model: 4\n",
            "num_heads: 2\n",
            "\n",
            "q.shape: (2, 10, 4)\n",
            "k.shape: (2, 10, 4)\n",
            "v.shape: (2, 10, 4)\n",
            "padding_mask.shape: (2, 1, 1, 10)\n",
            "output.shape: (2, 10, 4)\n",
            "attention_weights.shape: (2, 2, 10, 10)\n",
            "\n",
            "output: tf.Tensor(\n",
            "[[[-0.00188406  0.00275641  0.00785922  0.00252943]\n",
            "  [-0.00189291  0.00276091  0.0078742   0.00254755]\n",
            "  [-0.0018929   0.00276079  0.00786851  0.00253509]\n",
            "  [-0.00189504  0.00276643  0.00786667  0.00252852]\n",
            "  [-0.00188757  0.00275982  0.00785472  0.00251403]\n",
            "  [-0.00189399  0.00276457  0.00786153  0.00251864]\n",
            "  [-0.00188108  0.00275339  0.00785578  0.00252647]\n",
            "  [-0.00189277  0.00276312  0.00786285  0.00252348]\n",
            "  [-0.00189268  0.00276108  0.00786921  0.00253706]\n",
            "  [-0.00189268  0.00276108  0.00786921  0.00253706]]\n",
            "\n",
            " [[-0.00906753  0.01263724  0.01369008 -0.00134147]\n",
            "  [-0.00906953  0.01263836  0.01369151 -0.00133907]\n",
            "  [-0.00909208  0.01265678  0.01372468 -0.00131445]\n",
            "  [-0.00906895  0.01263639  0.01371735 -0.00130616]\n",
            "  [-0.00910613  0.01267141  0.01371127 -0.00134526]\n",
            "  [-0.00906618  0.01263407  0.01368675 -0.001341  ]\n",
            "  [-0.00906524  0.01262819  0.01367573 -0.00134565]\n",
            "  [-0.00906724  0.01263367  0.01367688 -0.00135421]\n",
            "  [-0.00909573  0.01266157  0.01373775 -0.00130237]\n",
            "  [-0.00909575  0.01265989  0.01370758 -0.00133698]]], shape=(2, 10, 4), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# emb_inp.shape == (batch_size, seq_len, d_model)\n",
        "#               == (2, 8, 4)\n",
        "assert d_model == emb_inp.shape[-1]  == 4\n",
        "num_heads = 2\n",
        "\n",
        "print(f\"d_model: {d_model}\")\n",
        "print(f\"num_heads: {num_heads}\\n\")\n",
        "\n",
        "# 初始化一個 multi-head attention layer\n",
        "mha = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "# 簡單將 v, k, q 都設置為 `emb_inp`\n",
        "# 順便看看 padding mask 的作用。\n",
        "# 別忘記，第一個中文序列的最後兩個 tokens 是 <pad>\n",
        "v = k = q = emb_inp\n",
        "padding_mask = create_padding_mask(inp)\n",
        "print(\"q.shape:\", q.shape)\n",
        "print(\"k.shape:\", k.shape)\n",
        "print(\"v.shape:\", v.shape)\n",
        "print(\"padding_mask.shape:\", padding_mask.shape)\n",
        "\n",
        "output, attention_weights = mha(v, k, q, mask)\n",
        "print(\"output.shape:\", output.shape)\n",
        "print(\"attention_weights.shape:\", attention_weights.shape)\n",
        "\n",
        "print(\"\\noutput:\", output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "37iC_QNcdtm1"
      },
      "outputs": [],
      "source": [
        "# 建立 Transformer 裡 Encoder / Decoder layer 都有使用到的 Feed Forward 元件\n",
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  \n",
        "  # 此 FFN 對輸入做兩個線性轉換，中間加了一個 ReLU activation func\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpgijJuUdvTz",
        "outputId": "c465ffd5-5207-4b8f-ce0d-7d02b742b5d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.shape: (64, 10, 512)\n",
            "out.shape: (64, 10, 512)\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "seq_len = 10\n",
        "d_model = 512\n",
        "dff = 2048\n",
        "\n",
        "x = tf.random.uniform((batch_size, seq_len, d_model))\n",
        "ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "out = ffn(x)\n",
        "print(\"x.shape:\", x.shape)\n",
        "print(\"out.shape:\", out.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRL1Hr8mdxOk",
        "outputId": "673c4ad8-2f53-4b4f-eb7f-fc89c385ae0b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
              "array([[ 2.8674245 , -2.174698  , -1.3073453 , -6.4233937 ],\n",
              "       [ 2.8674245 , -2.174698  , -1.3073453 , -6.4233937 ],\n",
              "       [ 3.6502066 , -0.97325826, -2.4126563 , -6.509499  ],\n",
              "       [ 3.6502066 , -0.97325826, -2.4126563 , -6.509499  ],\n",
              "       [ 3.6502066 , -0.97325826, -2.4126563 , -6.509499  ]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ],
      "source": [
        "d_model = 4 # FFN 的輸入輸出張量的最後一維皆為 `d_model`\n",
        "dff = 6\n",
        "\n",
        "# 建立一個小 FFN\n",
        "small_ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "# 懂子詞梗的站出來\n",
        "dummy_sentence = tf.constant([[5, 5, 6, 6], \n",
        "                              [5, 5, 6, 6], \n",
        "                              [9, 5, 2, 7], \n",
        "                              [9, 5, 2, 7],\n",
        "                              [9, 5, 2, 7]], dtype=tf.float32)\n",
        "small_ffn(dummy_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "1-854Nq_dy0Z"
      },
      "outputs": [],
      "source": [
        "# sub_layer_out = Sublayer(x)\n",
        "# sub_layer_out = Dropout(sub_layer_out)\n",
        "# out = LayerNorm(x + sub_layer_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "vS58Pa_ed0U0"
      },
      "outputs": [],
      "source": [
        "# Encoder 裡頭會有 N 個 EncoderLayers，而每個 EncoderLayer 裡又有兩個 sub-layers: MHA & FFN\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  # Transformer 論文內預設 dropout rate 為 0.1\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    # layer norm 很常在 RNN-based 的模型被使用。一個 sub-layer 一個 layer norm\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    # 一樣，一個 sub-layer 一個 dropout layer\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "  # 需要丟入 `training` 參數是因為 dropout 在訓練以及測試的行為有所不同\n",
        "  def call(self, x, training, mask):\n",
        "    # 除了 `attn`，其他張量的 shape 皆為 (batch_size, input_seq_len, d_model)\n",
        "    # attn.shape == (batch_size, num_heads, input_seq_len, input_seq_len)\n",
        "    \n",
        "    # sub-layer 1: MHA\n",
        "    # Encoder 利用注意機制關注自己當前的序列，因此 v, k, q 全部都是自己\n",
        "    # 另外別忘了我們還需要 padding mask 來遮住輸入序列中的 <pad> token\n",
        "    attn_output, attn = self.mha(x, x, x, mask)  \n",
        "    attn_output = self.dropout1(attn_output, training=training) \n",
        "    out1 = self.layernorm1(x + attn_output)  \n",
        "    \n",
        "    # sub-layer 2: FFN\n",
        "    ffn_output = self.ffn(out1) \n",
        "    ffn_output = self.dropout2(ffn_output, training=training)  # 記得 training\n",
        "    out2 = self.layernorm2(out1 + ffn_output)\n",
        "    \n",
        "    return out2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yovnlBAzd2kd",
        "outputId": "62abc6c4-c80a-4094-a97a-2ba516913b18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inp: tf.Tensor(\n",
            "[[8435    5 6516  146 3858 1672 8211 8436    0    0]\n",
            " [8435  345 1760  469 1131 2044 1817 6923   97 8436]], shape=(2, 10), dtype=int64)\n",
            "--------------------\n",
            "padding_mask: tf.Tensor(\n",
            "[[[[0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]]]\n",
            "\n",
            "\n",
            " [[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 1, 10), dtype=float32)\n",
            "--------------------\n",
            "emb_inp: tf.Tensor(\n",
            "[[[ 0.02935244  0.03554614  0.01736045  0.02575929]\n",
            "  [-0.03594353  0.01885075  0.03922334 -0.00784503]\n",
            "  [-0.03059219  0.01373898 -0.00424446 -0.02270319]\n",
            "  [ 0.04029178 -0.02860543  0.04083917 -0.03974632]\n",
            "  [ 0.03491883 -0.01808844 -0.00810398 -0.00344821]\n",
            "  [ 0.02062017 -0.04103831  0.00197386 -0.03821779]\n",
            "  [ 0.01965567  0.04608833 -0.00050522  0.04238245]\n",
            "  [ 0.02151975 -0.00338126 -0.00539899 -0.0355748 ]\n",
            "  [-0.02430863  0.01005951  0.01137512 -0.01772247]\n",
            "  [-0.02430863  0.01005951  0.01137512 -0.01772247]]\n",
            "\n",
            " [[ 0.02935244  0.03554614  0.01736045  0.02575929]\n",
            "  [ 0.03484343  0.04224272  0.03947636  0.01727359]\n",
            "  [-0.02818116 -0.0363391   0.00415504 -0.0146267 ]\n",
            "  [-0.03855926 -0.03173556  0.04078556  0.03262645]\n",
            "  [ 0.02185332  0.0097766  -0.04647985 -0.04552171]\n",
            "  [ 0.03356006  0.01610223  0.02188022  0.01938898]\n",
            "  [ 0.04685703 -0.04407927  0.00547624 -0.00190698]\n",
            "  [ 0.03725089 -0.02967271 -0.04921424  0.01288768]\n",
            "  [-0.04117537 -0.00766627  0.04484664 -0.0131226 ]\n",
            "  [ 0.02151975 -0.00338126 -0.00539899 -0.0355748 ]]], shape=(2, 10, 4), dtype=float32)\n",
            "--------------------\n",
            "enc_out: tf.Tensor(\n",
            "[[[ 1.1416198   0.79262084 -1.2816105  -0.65263003]\n",
            "  [-1.1407173   0.84364384  1.1341566  -0.8370831 ]\n",
            "  [-0.61303675  1.6764567  -0.17940527 -0.8840146 ]\n",
            "  [ 1.4787996  -0.44774088  0.21970192 -1.2507607 ]\n",
            "  [ 1.7115079  -0.803609   -0.5339671  -0.3739318 ]\n",
            "  [ 1.6248789  -0.6379019  -0.01090133 -0.9760756 ]\n",
            "  [-0.63065326  1.4080789  -1.2003138   0.4228881 ]\n",
            "  [ 1.4914534   0.2937328  -0.6736904  -1.1114957 ]\n",
            "  [-0.4057693   1.1343098   0.70420873 -1.4327492 ]\n",
            "  [-0.4057693   1.1343098   0.70420873 -1.4327492 ]]\n",
            "\n",
            " [[ 0.10096247  1.3667055  -1.4566395  -0.0110286 ]\n",
            "  [ 0.5880986   1.2744825  -0.5470899  -1.3154912 ]\n",
            "  [-0.40032244 -1.0239531   1.654732   -0.23045658]\n",
            "  [-1.2167714  -0.7559969   1.0181304   0.9546378 ]\n",
            "  [ 0.77225864  0.95934755 -1.5672427  -0.16436347]\n",
            "  [ 1.7215056  -0.50008357 -0.46859777 -0.7528242 ]\n",
            "  [ 1.5274152  -1.2785958  -0.1492522  -0.09956719]\n",
            "  [ 1.1990843  -0.44233435 -1.398227    0.6414772 ]\n",
            "  [-1.118516    0.3999797   1.4388008  -0.72026455]\n",
            "  [ 1.4224466   0.4541937  -0.86955374 -1.0070868 ]]], shape=(2, 10, 4), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# 之後可以調的超參數。這邊為了 demo 設小一點\n",
        "d_model = 4\n",
        "num_heads = 2\n",
        "dff = 8\n",
        "\n",
        "# 新建一個使用上述參數的 Encoder Layer\n",
        "enc_layer = EncoderLayer(d_model, num_heads, dff)\n",
        "padding_mask = create_padding_mask(inp)  # 建立一個當前輸入 batch 使用的 padding mask\n",
        "enc_out = enc_layer(emb_inp, training=False, mask=padding_mask)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "print(\"inp:\", inp)\n",
        "print(\"-\" * 20)\n",
        "print(\"padding_mask:\", padding_mask)\n",
        "print(\"-\" * 20)\n",
        "print(\"emb_inp:\", emb_inp)\n",
        "print(\"-\" * 20)\n",
        "print(\"enc_out:\", enc_out)\n",
        "assert emb_inp.shape == enc_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "PBzZ3Xeod4-1"
      },
      "outputs": [],
      "source": [
        "# sub_layer_out = Sublayer(x)\n",
        "# sub_layer_out = Dropout(sub_layer_out)\n",
        "# out = LayerNorm(x + sub_layer_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "bJIOtFNed7Y0"
      },
      "outputs": [],
      "source": [
        "# Decoder 裡頭會有 N 個 DecoderLayer，\n",
        "# 而 DecoderLayer 又有三個 sub-layers: 自注意的 MHA, 關注 Encoder 輸出的 MHA & FFN\n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    # 3 個 sub-layers 的主角們\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        " \n",
        "    # 定義每個 sub-layer 用的 LayerNorm\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    # 定義每個 sub-layer 用的 Dropout\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    \n",
        "  def call(self, x, enc_output, training, \n",
        "           combined_mask, inp_padding_mask):\n",
        "    # 所有 sub-layers 的主要輸出皆為 (batch_size, target_seq_len, d_model)\n",
        "    # enc_output 為 Encoder 輸出序列，shape 為 (batch_size, input_seq_len, d_model)\n",
        "    # attn_weights_block_1 則為 (batch_size, num_heads, target_seq_len, target_seq_len)\n",
        "    # attn_weights_block_2 則為 (batch_size, num_heads, target_seq_len, input_seq_len)\n",
        "\n",
        "    # sub-layer 1: Decoder layer 自己對輸出序列做注意力。\n",
        "    # 我們同時需要 look ahead mask 以及輸出序列的 padding mask \n",
        "    # 來避免前面已生成的子詞關注到未來的子詞以及 <pad>\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, combined_mask)\n",
        "    attn1 = self.dropout1(attn1, training=training)\n",
        "    out1 = self.layernorm1(attn1 + x)\n",
        "    \n",
        "    # sub-layer 2: Decoder layer 關注 Encoder 的最後輸出\n",
        "    # 記得我們一樣需要對 Encoder 的輸出套用 padding mask 避免關注到 <pad>\n",
        "    attn2, attn_weights_block2 = self.mha2(\n",
        "        enc_output, enc_output, out1, inp_padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn2 = self.dropout2(attn2, training=training)\n",
        "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "    \n",
        "    # sub-layer 3: FFN 部分跟 Encoder layer 完全一樣\n",
        "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    ffn_output = self.dropout3(ffn_output, training=training)\n",
        "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "    \n",
        "    # 除了主要輸出 `out3` 以外，輸出 multi-head 注意權重方便之後理解模型內部狀況\n",
        "    return out3, attn_weights_block1, attn_weights_block2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLiPXE9Od9LU",
        "outputId": "22ec63e7-8382-467c-a75e-c99ea7efe9e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tar: tf.Tensor(\n",
            "[[299 159 148  75 159 158 147 140 148  75 147 153 146  75 159 158 148 153\n",
            "  146  75 148 160  75 150 148  92  75 159 158 147 144 153 153  75 159 158\n",
            "  147 140 148 300   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0]\n",
            " [299 147 160 140 153  75 159 154  75 159 153 146  75 151 148  75 148 154\n",
            "  153 146  75 150 147 160 140 153  75 155 154  75 144  75 158 144 153 153\n",
            "   75 159 147 140 148  75 147 154 153 146  75 159 148  75 147 160 140 159\n",
            "  300]], shape=(2, 55), dtype=int64)\n",
            "--------------------\n",
            "tar_padding_mask: tf.Tensor(\n",
            "[[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "    0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
            "    1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]]\n",
            "\n",
            "\n",
            " [[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "    0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "    0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 1, 55), dtype=float32)\n",
            "--------------------\n",
            "look_ahead_mask: tf.Tensor(\n",
            "[[0. 1. 1. ... 1. 1. 1.]\n",
            " [0. 0. 1. ... 1. 1. 1.]\n",
            " [0. 0. 0. ... 1. 1. 1.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 1. 1.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 0.]], shape=(55, 55), dtype=float32)\n",
            "--------------------\n",
            "combined_mask: tf.Tensor(\n",
            "[[[[0. 1. 1. ... 1. 1. 1.]\n",
            "   [0. 0. 1. ... 1. 1. 1.]\n",
            "   [0. 0. 0. ... 1. 1. 1.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 1. 1. 1.]\n",
            "   [0. 0. 0. ... 1. 1. 1.]\n",
            "   [0. 0. 0. ... 1. 1. 1.]]]\n",
            "\n",
            "\n",
            " [[[0. 1. 1. ... 1. 1. 1.]\n",
            "   [0. 0. 1. ... 1. 1. 1.]\n",
            "   [0. 0. 0. ... 1. 1. 1.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 1. 1.]\n",
            "   [0. 0. 0. ... 0. 0. 1.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]]], shape=(2, 1, 55, 55), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "tar_padding_mask = create_padding_mask(tar)\n",
        "look_ahead_mask = create_look_ahead_mask(tar.shape[-1])\n",
        "combined_mask = tf.maximum(tar_padding_mask, look_ahead_mask)\n",
        "\n",
        "print(\"tar:\", tar)\n",
        "print(\"-\" * 20)\n",
        "print(\"tar_padding_mask:\", tar_padding_mask)\n",
        "print(\"-\" * 20)\n",
        "print(\"look_ahead_mask:\", look_ahead_mask)\n",
        "print(\"-\" * 20)\n",
        "print(\"combined_mask:\", combined_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "Hhw6j82Ud9Wo"
      },
      "outputs": [],
      "source": [
        "# (batch_size, num_heads, seq_len_tar, seq_len_tar)\n",
        "# = (2, 1, 10, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYlGdeOrd_bg",
        "outputId": "a2f128af-a0f6-4036-dc80-a74b6af5dfa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emb_tar: tf.Tensor(\n",
            "[[[-0.0190919  -0.00201263 -0.01303856 -0.02510204]\n",
            "  [-0.02460332  0.00036935  0.04674867  0.01960564]\n",
            "  [ 0.02463751  0.00880463 -0.00514092 -0.03603983]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [-0.02460332  0.00036935  0.04674867  0.01960564]\n",
            "  [ 0.00856012 -0.01226419  0.02874683 -0.04015855]\n",
            "  [-0.02816296  0.00966698 -0.00221155  0.0073831 ]\n",
            "  [ 0.02771181  0.04394838  0.01171549 -0.04838048]\n",
            "  [ 0.02463751  0.00880463 -0.00514092 -0.03603983]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [-0.02816296  0.00966698 -0.00221155  0.0073831 ]\n",
            "  [-0.00686067  0.04643979 -0.0413846  -0.02162947]\n",
            "  [-0.01786237  0.00560535 -0.04371337  0.02780685]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [-0.02460332  0.00036935  0.04674867  0.01960564]\n",
            "  [ 0.00856012 -0.01226419  0.02874683 -0.04015855]\n",
            "  [ 0.02463751  0.00880463 -0.00514092 -0.03603983]\n",
            "  [-0.00686067  0.04643979 -0.0413846  -0.02162947]\n",
            "  [-0.01786237  0.00560535 -0.04371337  0.02780685]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [ 0.02463751  0.00880463 -0.00514092 -0.03603983]\n",
            "  [ 0.02972369 -0.04810737 -0.03303741  0.04613603]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [ 0.04480283  0.038434   -0.04184365  0.02166598]\n",
            "  [ 0.02463751  0.00880463 -0.00514092 -0.03603983]\n",
            "  [-0.01177984 -0.03202578  0.03309724 -0.02195791]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [-0.02460332  0.00036935  0.04674867  0.01960564]\n",
            "  [ 0.00856012 -0.01226419  0.02874683 -0.04015855]\n",
            "  [-0.02816296  0.00966698 -0.00221155  0.0073831 ]\n",
            "  [ 0.01204687 -0.04859294  0.0436013   0.03561128]\n",
            "  [-0.00686067  0.04643979 -0.0413846  -0.02162947]\n",
            "  [-0.00686067  0.04643979 -0.0413846  -0.02162947]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [-0.02460332  0.00036935  0.04674867  0.01960564]\n",
            "  [ 0.00856012 -0.01226419  0.02874683 -0.04015855]\n",
            "  [-0.02816296  0.00966698 -0.00221155  0.0073831 ]\n",
            "  [ 0.02771181  0.04394838  0.01171549 -0.04838048]\n",
            "  [ 0.02463751  0.00880463 -0.00514092 -0.03603983]\n",
            "  [ 0.04444501 -0.03202839 -0.0314198  -0.04058455]\n",
            "  [ 0.03725791  0.04257536  0.00082171  0.00264676]\n",
            "  [ 0.03725791  0.04257536  0.00082171  0.00264676]\n",
            "  [ 0.03725791  0.04257536  0.00082171  0.00264676]\n",
            "  [ 0.03725791  0.04257536  0.00082171  0.00264676]\n",
            "  [ 0.03725791  0.04257536  0.00082171  0.00264676]\n",
            "  [ 0.03725791  0.04257536  0.00082171  0.00264676]\n",
            "  [ 0.03725791  0.04257536  0.00082171  0.00264676]\n",
            "  [ 0.03725791  0.04257536  0.00082171  0.00264676]\n",
            "  [ 0.03725791  0.04257536  0.00082171  0.00264676]\n",
            "  [ 0.03725791  0.04257536  0.00082171  0.00264676]\n",
            "  [ 0.03725791  0.04257536  0.00082171  0.00264676]\n",
            "  [ 0.03725791  0.04257536  0.00082171  0.00264676]\n",
            "  [ 0.03725791  0.04257536  0.00082171  0.00264676]\n",
            "  [ 0.03725791  0.04257536  0.00082171  0.00264676]\n",
            "  [ 0.03725791  0.04257536  0.00082171  0.00264676]]\n",
            "\n",
            " [[-0.0190919  -0.00201263 -0.01303856 -0.02510204]\n",
            "  [-0.02816296  0.00966698 -0.00221155  0.0073831 ]\n",
            "  [ 0.02972369 -0.04810737 -0.03303741  0.04613603]\n",
            "  [ 0.02771181  0.04394838  0.01171549 -0.04838048]\n",
            "  [-0.00686067  0.04643979 -0.0413846  -0.02162947]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [-0.02460332  0.00036935  0.04674867  0.01960564]\n",
            "  [-0.00915013 -0.00927166  0.00793984  0.00561764]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [-0.02460332  0.00036935  0.04674867  0.01960564]\n",
            "  [-0.00686067  0.04643979 -0.0413846  -0.02162947]\n",
            "  [-0.01786237  0.00560535 -0.04371337  0.02780685]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [ 0.03892842 -0.01577774  0.00067146  0.04548496]\n",
            "  [ 0.02463751  0.00880463 -0.00514092 -0.03603983]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [ 0.02463751  0.00880463 -0.00514092 -0.03603983]\n",
            "  [-0.00915013 -0.00927166  0.00793984  0.00561764]\n",
            "  [-0.00686067  0.04643979 -0.0413846  -0.02162947]\n",
            "  [-0.01786237  0.00560535 -0.04371337  0.02780685]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [ 0.04480283  0.038434   -0.04184365  0.02166598]\n",
            "  [-0.02816296  0.00966698 -0.00221155  0.0073831 ]\n",
            "  [ 0.02972369 -0.04810737 -0.03303741  0.04613603]\n",
            "  [ 0.02771181  0.04394838  0.01171549 -0.04838048]\n",
            "  [-0.00686067  0.04643979 -0.0413846  -0.02162947]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [ 0.00101025  0.00090782 -0.00990582 -0.00317892]\n",
            "  [-0.00915013 -0.00927166  0.00793984  0.00561764]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [ 0.01204687 -0.04859294  0.0436013   0.03561128]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [ 0.00856012 -0.01226419  0.02874683 -0.04015855]\n",
            "  [ 0.01204687 -0.04859294  0.0436013   0.03561128]\n",
            "  [-0.00686067  0.04643979 -0.0413846  -0.02162947]\n",
            "  [-0.00686067  0.04643979 -0.0413846  -0.02162947]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [-0.02460332  0.00036935  0.04674867  0.01960564]\n",
            "  [-0.02816296  0.00966698 -0.00221155  0.0073831 ]\n",
            "  [ 0.02771181  0.04394838  0.01171549 -0.04838048]\n",
            "  [ 0.02463751  0.00880463 -0.00514092 -0.03603983]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [-0.02816296  0.00966698 -0.00221155  0.0073831 ]\n",
            "  [-0.00915013 -0.00927166  0.00793984  0.00561764]\n",
            "  [-0.00686067  0.04643979 -0.0413846  -0.02162947]\n",
            "  [-0.01786237  0.00560535 -0.04371337  0.02780685]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [-0.02460332  0.00036935  0.04674867  0.01960564]\n",
            "  [ 0.02463751  0.00880463 -0.00514092 -0.03603983]\n",
            "  [-0.04945021  0.03963875 -0.04859821  0.00969683]\n",
            "  [-0.02816296  0.00966698 -0.00221155  0.0073831 ]\n",
            "  [ 0.02972369 -0.04810737 -0.03303741  0.04613603]\n",
            "  [ 0.02771181  0.04394838  0.01171549 -0.04838048]\n",
            "  [-0.02460332  0.00036935  0.04674867  0.01960564]\n",
            "  [ 0.04444501 -0.03202839 -0.0314198  -0.04058455]]], shape=(2, 55, 4), dtype=float32)\n",
            "--------------------\n",
            "enc_out: tf.Tensor(\n",
            "[[[ 1.1416198   0.79262084 -1.2816105  -0.65263003]\n",
            "  [-1.1407173   0.84364384  1.1341566  -0.8370831 ]\n",
            "  [-0.61303675  1.6764567  -0.17940527 -0.8840146 ]\n",
            "  [ 1.4787996  -0.44774088  0.21970192 -1.2507607 ]\n",
            "  [ 1.7115079  -0.803609   -0.5339671  -0.3739318 ]\n",
            "  [ 1.6248789  -0.6379019  -0.01090133 -0.9760756 ]\n",
            "  [-0.63065326  1.4080789  -1.2003138   0.4228881 ]\n",
            "  [ 1.4914534   0.2937328  -0.6736904  -1.1114957 ]\n",
            "  [-0.4057693   1.1343098   0.70420873 -1.4327492 ]\n",
            "  [-0.4057693   1.1343098   0.70420873 -1.4327492 ]]\n",
            "\n",
            " [[ 0.10096247  1.3667055  -1.4566395  -0.0110286 ]\n",
            "  [ 0.5880986   1.2744825  -0.5470899  -1.3154912 ]\n",
            "  [-0.40032244 -1.0239531   1.654732   -0.23045658]\n",
            "  [-1.2167714  -0.7559969   1.0181304   0.9546378 ]\n",
            "  [ 0.77225864  0.95934755 -1.5672427  -0.16436347]\n",
            "  [ 1.7215056  -0.50008357 -0.46859777 -0.7528242 ]\n",
            "  [ 1.5274152  -1.2785958  -0.1492522  -0.09956719]\n",
            "  [ 1.1990843  -0.44233435 -1.398227    0.6414772 ]\n",
            "  [-1.118516    0.3999797   1.4388008  -0.72026455]\n",
            "  [ 1.4224466   0.4541937  -0.86955374 -1.0070868 ]]], shape=(2, 10, 4), dtype=float32)\n",
            "--------------------\n",
            "dec_out: tf.Tensor(\n",
            "[[[-0.8997471   0.9881185   1.0070443  -1.0954158 ]\n",
            "  [-1.1597092  -0.8250046   0.9428865   1.0418271 ]\n",
            "  [ 1.3868628   0.37448427 -1.3195353  -0.4418118 ]\n",
            "  [-1.2283838   1.4160755  -0.57767683  0.38998505]\n",
            "  [-1.3579676  -0.52300787  1.1785506   0.7024248 ]\n",
            "  [ 1.1469977  -1.447598    0.6716796  -0.37107927]\n",
            "  [-1.6701478   0.71733075  0.12848037  0.82433677]\n",
            "  [ 0.5493679   1.3541847  -0.78957486 -1.1139778 ]\n",
            "  [ 1.289654    0.5346472  -1.3519831  -0.4723181 ]\n",
            "  [-1.3107104   1.3504455  -0.49816644  0.45843142]\n",
            "  [-1.7068983   0.82367283  0.34671295  0.53651255]\n",
            "  [-0.448739    1.6128101  -1.0919089  -0.07216227]\n",
            "  [-0.68121207  0.48716575 -1.1835606   1.3776071 ]\n",
            "  [-1.2061545   1.4551722  -0.569849    0.32083142]\n",
            "  [-1.4075514  -0.32589257  1.319588    0.41385603]\n",
            "  [ 1.2797511  -0.75270855  0.6466367  -1.1736794 ]\n",
            "  [ 1.1066786   0.7912698  -1.3661356  -0.5318129 ]\n",
            "  [-0.4479724   1.6261688  -1.0691079  -0.10908842]\n",
            "  [-0.6930145   0.51760775 -1.1843867   1.3597935 ]\n",
            "  [-1.2180505   1.458056   -0.5452204   0.3052147 ]\n",
            "  [ 1.0394965   0.8942673  -1.3204412  -0.6133226 ]\n",
            "  [ 0.30926612 -0.76810855 -1.0372858   1.4961282 ]\n",
            "  [-1.2235241   1.4787233  -0.5042944   0.24909526]\n",
            "  [ 0.08105747  0.8526398  -1.6564994   0.72280204]\n",
            "  [ 0.98569536  0.98062766 -1.241578   -0.72474515]\n",
            "  [-0.4246441  -1.3684818   1.3084378   0.4846882 ]\n",
            "  [-1.2398354   1.4800478  -0.46896958  0.2287572 ]\n",
            "  [-1.4039674  -0.23411918  1.381358    0.25672847]\n",
            "  [ 0.96663076 -0.4262243   0.8998255  -1.440232  ]\n",
            "  [-1.5948466   1.1093681   0.4750283   0.01045014]\n",
            "  [ 0.07734546 -1.4633272   0.02507768  1.360904  ]\n",
            "  [-0.44776544  1.6473426  -1.0277324  -0.17184457]\n",
            "  [-0.449831    1.6506097  -1.0200329  -0.18074602]\n",
            "  [-1.2329264   1.4713914  -0.49769124  0.25922617]\n",
            "  [-1.4047757  -0.2561714   1.3697343   0.29121283]\n",
            "  [ 1.0467579  -0.44966212  0.82480323 -1.421899  ]\n",
            "  [-1.5978565   1.1215427   0.43252045  0.04379326]\n",
            "  [ 0.39762843  1.4359962  -0.69464934 -1.1389753 ]\n",
            "  [ 1.0592461   0.8814434  -1.300432   -0.6402576 ]\n",
            "  [ 1.3539175  -0.30110645 -1.3987687   0.34595743]\n",
            "  [ 0.26027265  1.3324776  -1.4628328  -0.12991741]\n",
            "  [ 0.26027265  1.3324776  -1.4628328  -0.12991741]\n",
            "  [ 0.26027265  1.3324776  -1.4628328  -0.12991741]\n",
            "  [ 0.26027265  1.3324776  -1.4628328  -0.12991741]\n",
            "  [ 0.26027265  1.3324776  -1.4628328  -0.12991741]\n",
            "  [ 0.26027265  1.3324776  -1.4628328  -0.12991741]\n",
            "  [ 0.26027265  1.3324776  -1.4628328  -0.12991741]\n",
            "  [ 0.26027265  1.3324776  -1.4628328  -0.12991741]\n",
            "  [ 0.26027265  1.3324776  -1.4628328  -0.12991741]\n",
            "  [ 0.26027265  1.3324776  -1.4628328  -0.12991741]\n",
            "  [ 0.26027265  1.3324776  -1.4628328  -0.12991741]\n",
            "  [ 0.26027265  1.3324776  -1.4628328  -0.12991741]\n",
            "  [ 0.26027274  1.3324776  -1.4628329  -0.1299175 ]\n",
            "  [ 0.26027274  1.3324776  -1.4628329  -0.1299175 ]\n",
            "  [ 0.26027274  1.3324776  -1.4628329  -0.1299175 ]]\n",
            "\n",
            " [[-0.57881504  0.96005195  0.9649331  -1.3461701 ]\n",
            "  [-1.5182549   1.0068437   0.78029764 -0.2688865 ]\n",
            "  [ 0.40628493 -0.8953618  -0.9624534   1.4515302 ]\n",
            "  [ 0.32237443  1.3592796  -0.27760005 -1.404054  ]\n",
            "  [-0.24505177  1.6937665  -0.828555   -0.6201596 ]\n",
            "  [-0.7685239   1.7061322  -0.2971561  -0.64045215]\n",
            "  [-0.9399465  -0.5677478   1.6642283  -0.15653408]\n",
            "  [-0.7069118  -1.2449527   1.1267259   0.82513845]\n",
            "  [-0.6976503   1.7262613  -0.56057477 -0.46803603]\n",
            "  [-0.9631437  -0.58308446  1.6497415  -0.10351339]\n",
            "  [-0.1494931   1.6199605  -1.1041771  -0.3662904 ]\n",
            "  [-0.18252483  0.6546446  -1.5450048   1.072885  ]\n",
            "  [-0.61887467  1.7280194  -0.64356136 -0.46558335]\n",
            "  [ 0.53183776 -0.66610116 -1.2104523   1.3447157 ]\n",
            "  [ 0.8958183   1.0911875  -1.1214103  -0.86559534]\n",
            "  [-0.64686155  1.7302147  -0.56508267 -0.5182705 ]\n",
            "  [ 0.8930731   1.0957491  -1.1040559  -0.8847663 ]\n",
            "  [-0.9775727   0.02115811  1.6154269  -0.6590123 ]\n",
            "  [-0.17117539  1.6479545  -1.0251849  -0.45159426]\n",
            "  [-0.23917761  0.7581619  -1.5309695   1.0119853 ]\n",
            "  [-0.65385175  1.7300224  -0.5235144  -0.55265635]\n",
            "  [ 0.21074373  0.9392432  -1.6732128   0.5232258 ]\n",
            "  [-0.82186216  1.3529894   0.5569053  -1.0880327 ]\n",
            "  [ 0.40487534 -0.7420649  -1.1019493   1.4391389 ]\n",
            "  [ 0.36123982  1.4304653  -0.56557435 -1.2261307 ]\n",
            "  [-0.18220115  1.6611937  -0.97774553 -0.5012469 ]\n",
            "  [-0.6652638   1.7269694  -0.45539597 -0.60630953]\n",
            "  [ 0.15349144  1.460701   -1.3267026  -0.28748995]\n",
            "  [-0.7280717   0.5812388   1.3226742  -1.1758412 ]\n",
            "  [-0.66112757  1.7281003  -0.47282475 -0.594148  ]\n",
            "  [ 0.08985572 -1.5666146   0.26549745  1.2112614 ]\n",
            "  [-0.65469205  1.7293286  -0.4962354  -0.5784011 ]\n",
            "  [ 0.63171196  0.52866846  0.5705063  -1.7308868 ]\n",
            "  [ 0.0901857  -1.5638638   0.25708342  1.2165945 ]\n",
            "  [-0.17351869  1.6521956  -1.0103511  -0.46832582]\n",
            "  [-0.17527577  1.65388    -1.0046519  -0.47395244]\n",
            "  [-0.6777487   1.7278161  -0.48040026 -0.56966704]\n",
            "  [-0.92136717 -0.3591054   1.6895972  -0.40912464]\n",
            "  [-0.9033191   1.3249915   0.60754776 -1.0292201 ]\n",
            "  [ 0.39391005  1.421459   -0.610613   -1.2047561 ]\n",
            "  [ 0.89928865  1.0917671  -1.0881839  -0.9028719 ]\n",
            "  [-0.7004756   1.726719   -0.48880124 -0.5374422 ]\n",
            "  [-0.9597787   1.283871    0.66800743 -0.9920997 ]\n",
            "  [-0.96225816  0.10994548  1.5877821  -0.73546946]\n",
            "  [-0.16986462  1.6465226  -1.0297445  -0.44691333]\n",
            "  [-0.2390156   0.7264843  -1.5275327   1.0400641 ]\n",
            "  [-0.6789329   1.7285326  -0.5108063  -0.53879344]\n",
            "  [-0.929607   -0.38374764  1.6877241  -0.37436956]\n",
            "  [ 0.89670527  1.0915592  -1.1120679  -0.8761963 ]\n",
            "  [-0.6828073   1.7283492  -0.5221828  -0.52335906]\n",
            "  [-0.9253891   1.3292404   0.6028176  -1.0066689 ]\n",
            "  [ 0.39447775 -0.7735871  -1.0702242   1.4493335 ]\n",
            "  [ 0.39481348  1.4208529  -0.6103656  -1.2053009 ]\n",
            "  [-0.93344975 -0.42103615  1.6857272  -0.3312414 ]\n",
            "  [ 1.3551853   0.10428543 -1.4671525   0.0076818 ]]], shape=(2, 55, 4), dtype=float32)\n",
            "--------------------\n",
            "dec_self_attn_weights.shape: (2, 2, 55, 55)\n",
            "dec_enc_attn_weights: (2, 2, 55, 10)\n"
          ]
        }
      ],
      "source": [
        "# 超參數\n",
        "d_model = 4\n",
        "num_heads = 2\n",
        "dff = 8\n",
        "dec_layer = DecoderLayer(d_model, num_heads, dff)\n",
        "\n",
        "# 來源、目標語言的序列都需要 padding mask\n",
        "inp_padding_mask = create_padding_mask(inp)\n",
        "tar_padding_mask = create_padding_mask(tar)\n",
        "\n",
        "# masked MHA 用的遮罩，把 padding 跟未來子詞都蓋住\n",
        "look_ahead_mask = create_look_ahead_mask(tar.shape[-1])\n",
        "combined_mask = tf.maximum(tar_padding_mask, look_ahead_mask)\n",
        "\n",
        "# 實際初始一個 decoder layer 並做 3 個 sub-layers 的計算\n",
        "dec_out, dec_self_attn_weights, dec_enc_attn_weights = dec_layer(\n",
        "    emb_tar, enc_out, False, combined_mask, inp_padding_mask)\n",
        "\n",
        "print(\"emb_tar:\", emb_tar)\n",
        "print(\"-\" * 20)\n",
        "print(\"enc_out:\", enc_out)\n",
        "print(\"-\" * 20)\n",
        "print(\"dec_out:\", dec_out)\n",
        "assert emb_tar.shape == dec_out.shape\n",
        "print(\"-\" * 20)\n",
        "print(\"dec_self_attn_weights.shape:\", dec_self_attn_weights.shape)\n",
        "print(\"dec_enc_attn_weights:\", dec_enc_attn_weights.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_zKFYVdDv70",
        "outputId": "24babd56-a97f-4e1f-f69f-144eeb5e8cf7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 50, 512), dtype=float32, numpy=\n",
              "array([[[ 0.        ,  0.        ,  0.        , ...,  1.        ,\n",
              "          1.        ,  1.        ],\n",
              "        [ 0.84147096,  0.8218562 ,  0.8019618 , ...,  1.        ,\n",
              "          1.        ,  1.        ],\n",
              "        [ 0.9092974 ,  0.9364147 ,  0.95814437, ...,  1.        ,\n",
              "          1.        ,  1.        ],\n",
              "        ...,\n",
              "        [ 0.12357312,  0.97718984, -0.24295525, ...,  0.9999863 ,\n",
              "          0.99998724,  0.99998814],\n",
              "        [-0.76825464,  0.7312359 ,  0.63279754, ...,  0.9999857 ,\n",
              "          0.9999867 ,  0.9999876 ],\n",
              "        [-0.95375264, -0.14402692,  0.99899054, ...,  0.9999851 ,\n",
              "          0.9999861 ,  0.9999871 ]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ],
      "source": [
        "# 以下直接參考 TensorFlow 官方 tutorial \n",
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "  \n",
        "  # apply sin to even indices in the array; 2i\n",
        "  sines = np.sin(angle_rads[:, 0::2])\n",
        "  \n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  cosines = np.cos(angle_rads[:, 1::2])\n",
        "  \n",
        "  pos_encoding = np.concatenate([sines, cosines], axis=-1)\n",
        "  \n",
        "  pos_encoding = pos_encoding[np.newaxis, ...]\n",
        "    \n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "\n",
        "seq_len = 50\n",
        "d_model = 512\n",
        "\n",
        "pos_encoding = positional_encoding(seq_len, d_model)\n",
        "pos_encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "vF-ydhPxDw0H",
        "outputId": "bd2d4d68-2f09-4416-b461-10efdb0867ba"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
        "plt.xlabel('d_model')\n",
        "plt.xlim((0, 512))\n",
        "plt.ylabel('Position')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "GLsNeqrTDzsN"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  # Encoder 的初始參數除了本來就要給 EncoderLayer 的參數還多了：\n",
        "  # - num_layers: 決定要有幾個 EncoderLayers, 前面影片中的 `N`\n",
        "  # - input_vocab_size: 用來把索引轉成詞嵌入向量\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
        "               rate=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(input_vocab_size, self.d_model)\n",
        "    \n",
        "    # 建立 `num_layers` 個 EncoderLayers\n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        \n",
        "  def call(self, x, training, mask):\n",
        "    # 輸入的 x.shape == (batch_size, input_seq_len)\n",
        "    # 以下各 layer 的輸出皆為 (batch_size, input_seq_len, d_model)\n",
        "    input_seq_len = tf.shape(x)[1]\n",
        "    \n",
        "    # 將 2 維的索引序列轉成 3 維的詞嵌入張量，並依照論文乘上 sqrt(d_model)\n",
        "    # 再加上對應長度的位置編碼\n",
        "    x = self.embedding(x)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :input_seq_len, :]\n",
        "\n",
        "    # 對 embedding 跟位置編碼的總合做 regularization\n",
        "    # 這在 Decoder 也會做\n",
        "    x = self.dropout(x, training=training)\n",
        "    \n",
        "    # 通過 N 個 EncoderLayer 做編碼\n",
        "    for i, enc_layer in enumerate(self.enc_layers):\n",
        "      x = enc_layer(x, training, mask)\n",
        "      # 以下只是用來 demo EncoderLayer outputs\n",
        "      #print('-' * 20)\n",
        "      #print(f\"EncoderLayer {i + 1}'s output:\", x)\n",
        "      \n",
        "    \n",
        "    return x "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVdxpspwD2uz",
        "outputId": "60a7d615-b398-4ba3-ad89-ffd5687ad586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inp: tf.Tensor(\n",
            "[[8435    5 6516  146 3858 1672 8211 8436    0    0]\n",
            " [8435  345 1760  469 1131 2044 1817 6923   97 8436]], shape=(2, 10), dtype=int64)\n",
            "--------------------\n",
            "enc_out: tf.Tensor(\n",
            "[[[-0.83610994 -0.5481087  -0.31845003  1.7026687 ]\n",
            "  [-0.58057255 -0.4860412  -0.66207147  1.7286853 ]\n",
            "  [-0.42363334 -0.03565829 -1.1330314   1.592323  ]\n",
            "  [-0.5961983   0.37365934 -1.2078502   1.4303892 ]\n",
            "  [-0.9248689   0.23986341 -0.85174567  1.5367513 ]\n",
            "  [-1.0248368  -0.15107548 -0.46927926  1.6451916 ]\n",
            "  [-0.9004431  -0.495825   -0.2939778   1.6902459 ]\n",
            "  [-0.693853   -0.49514955 -0.53831035  1.7273129 ]\n",
            "  [-0.39859828 -0.13082337 -1.0924646   1.6218864 ]\n",
            "  [-0.49760455  0.35903174 -1.274937    1.4135098 ]]\n",
            "\n",
            " [[-0.82740587 -0.58240277 -0.2906911   1.7004997 ]\n",
            "  [-0.5849646  -0.556896   -0.59005064  1.7319112 ]\n",
            "  [-0.3260328  -0.00793445 -1.2182711   1.5522383 ]\n",
            "  [-0.5846866   0.39317098 -1.2243195   1.4158351 ]\n",
            "  [-0.89239967  0.21091054 -0.8689904   1.5504795 ]\n",
            "  [-1.0038097  -0.18767962 -0.46428183  1.6557711 ]\n",
            "  [-0.89741755 -0.5098136  -0.28243113  1.6896622 ]\n",
            "  [-0.63237566 -0.59860104 -0.4989888   1.7299654 ]\n",
            "  [-0.33041584 -0.06353718 -1.1830919   1.577045  ]\n",
            "  [-0.49682358  0.47738302 -1.3178849   1.3373256 ]]], shape=(2, 10, 4), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# 超參數\n",
        "num_layers = 2 # 2 層的 Encoder\n",
        "d_model = 4\n",
        "num_heads = 2\n",
        "dff = 8\n",
        "input_vocab_size = subword_encoder_ch.vocab_size + 2 # 記得加上 <start>, <end>\n",
        "\n",
        "# 初始化一個 Encoder\n",
        "encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size)\n",
        "\n",
        "# 將 2 維的索引序列丟入 Encoder 做編碼\n",
        "enc_out = encoder(inp, training=False, mask=None)\n",
        "print(\"inp:\", inp)\n",
        "print(\"-\" * 20)\n",
        "print(\"enc_out:\", enc_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "uJOZYmJnD4dt"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  # 初始參數跟 Encoder 只差在用 `target_vocab_size` 而非 `inp_vocab_size`\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, \n",
        "               rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    \n",
        "    # 為中文（目標語言）建立詞嵌入層\n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(target_vocab_size, self.d_model)\n",
        "    \n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "  \n",
        "  # 呼叫時的參數跟 DecoderLayer 一模一樣\n",
        "  def call(self, x, enc_output, training, \n",
        "           combined_mask, inp_padding_mask):\n",
        "    \n",
        "    tar_seq_len = tf.shape(x)[1]\n",
        "    attention_weights = {}  # 用來存放每個 Decoder layer 的注意權重\n",
        "    \n",
        "    # 這邊跟 Encoder 做的事情完全一樣\n",
        "    x = self.embedding(x)  # (batch_size, tar_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :tar_seq_len, :]\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    \n",
        "    for i, dec_layer in enumerate(self.dec_layers):\n",
        "      x, block1, block2 = dec_layer(x, enc_output, training,\n",
        "                                    combined_mask, inp_padding_mask)\n",
        "      \n",
        "      # 將從每個 Decoder layer 取得的注意權重全部存下來回傳，方便我們觀察\n",
        "      attention_weights['decoder_layer{}_block1'.format(i + 1)] = block1\n",
        "      attention_weights['decoder_layer{}_block2'.format(i + 1)] = block2\n",
        "    \n",
        "    # x.shape == (batch_size, tar_seq_len, d_model)\n",
        "    return x, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2huetFIHD7Jo",
        "outputId": "50faae73-d285-42f8-ba3f-f5fbce894007"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tar: tf.Tensor(\n",
            "[[299 159 148  75 159 158 147 140 148  75 147 153 146  75 159 158 148 153\n",
            "  146  75 148 160  75 150 148  92  75 159 158 147 144 153 153  75 159 158\n",
            "  147 140 148 300   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0]\n",
            " [299 147 160 140 153  75 159 154  75 159 153 146  75 151 148  75 148 154\n",
            "  153 146  75 150 147 160 140 153  75 155 154  75 144  75 158 144 153 153\n",
            "   75 159 147 140 148  75 147 154 153 146  75 159 148  75 147 160 140 159\n",
            "  300]], shape=(2, 55), dtype=int64)\n",
            "--------------------\n",
            "combined_mask: tf.Tensor(\n",
            "[[[[0. 1. 1. ... 1. 1. 1.]\n",
            "   [0. 0. 1. ... 1. 1. 1.]\n",
            "   [0. 0. 0. ... 1. 1. 1.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 1. 1. 1.]\n",
            "   [0. 0. 0. ... 1. 1. 1.]\n",
            "   [0. 0. 0. ... 1. 1. 1.]]]\n",
            "\n",
            "\n",
            " [[[0. 1. 1. ... 1. 1. 1.]\n",
            "   [0. 0. 1. ... 1. 1. 1.]\n",
            "   [0. 0. 0. ... 1. 1. 1.]\n",
            "   ...\n",
            "   [0. 0. 0. ... 0. 1. 1.]\n",
            "   [0. 0. 0. ... 0. 0. 1.]\n",
            "   [0. 0. 0. ... 0. 0. 0.]]]], shape=(2, 1, 55, 55), dtype=float32)\n",
            "--------------------\n",
            "enc_out: tf.Tensor(\n",
            "[[[-0.83610994 -0.5481087  -0.31845003  1.7026687 ]\n",
            "  [-0.58057255 -0.4860412  -0.66207147  1.7286853 ]\n",
            "  [-0.42363334 -0.03565829 -1.1330314   1.592323  ]\n",
            "  [-0.5961983   0.37365934 -1.2078502   1.4303892 ]\n",
            "  [-0.9248689   0.23986341 -0.85174567  1.5367513 ]\n",
            "  [-1.0248368  -0.15107548 -0.46927926  1.6451916 ]\n",
            "  [-0.9004431  -0.495825   -0.2939778   1.6902459 ]\n",
            "  [-0.693853   -0.49514955 -0.53831035  1.7273129 ]\n",
            "  [-0.39859828 -0.13082337 -1.0924646   1.6218864 ]\n",
            "  [-0.49760455  0.35903174 -1.274937    1.4135098 ]]\n",
            "\n",
            " [[-0.82740587 -0.58240277 -0.2906911   1.7004997 ]\n",
            "  [-0.5849646  -0.556896   -0.59005064  1.7319112 ]\n",
            "  [-0.3260328  -0.00793445 -1.2182711   1.5522383 ]\n",
            "  [-0.5846866   0.39317098 -1.2243195   1.4158351 ]\n",
            "  [-0.89239967  0.21091054 -0.8689904   1.5504795 ]\n",
            "  [-1.0038097  -0.18767962 -0.46428183  1.6557711 ]\n",
            "  [-0.89741755 -0.5098136  -0.28243113  1.6896622 ]\n",
            "  [-0.63237566 -0.59860104 -0.4989888   1.7299654 ]\n",
            "  [-0.33041584 -0.06353718 -1.1830919   1.577045  ]\n",
            "  [-0.49682358  0.47738302 -1.3178849   1.3373256 ]]], shape=(2, 10, 4), dtype=float32)\n",
            "--------------------\n",
            "inp_padding_mask: tf.Tensor(\n",
            "[[[[0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]]]\n",
            "\n",
            "\n",
            " [[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 1, 10), dtype=float32)\n",
            "--------------------\n",
            "dec_out: tf.Tensor(\n",
            "[[[-5.93627214e-01 -1.04143333e+00  1.60057223e+00  3.44881341e-02]\n",
            "  [-3.17337215e-01 -1.23464882e+00  1.54104424e+00  1.09418742e-02]\n",
            "  [ 8.83285999e-02 -1.37875307e+00  1.43850875e+00 -1.48084223e-01]\n",
            "  [ 2.11522803e-02 -1.36042118e+00  1.46083069e+00 -1.21561706e-01]\n",
            "  [-3.83289754e-01 -1.08657181e+00  1.62717581e+00 -1.57314360e-01]\n",
            "  [-4.16138619e-01 -1.03029919e+00  1.65037036e+00 -2.03932464e-01]\n",
            "  [-3.45905781e-01 -1.03722441e+00  1.65281141e+00 -2.69681275e-01]\n",
            "  [-2.01573074e-01 -1.13420832e+00  1.61149597e+00 -2.75714785e-01]\n",
            "  [ 1.68309674e-01 -1.33888853e+00  1.44955802e+00 -2.78979093e-01]\n",
            "  [ 1.56966910e-01 -1.39269698e+00  1.41543651e+00 -1.79706514e-01]\n",
            "  [-3.59942168e-01 -1.15783536e+00  1.58895862e+00 -7.11811185e-02]\n",
            "  [-4.22576249e-01 -1.03599572e+00  1.64700723e+00 -1.88435495e-01]\n",
            "  [-3.54658246e-01 -1.03081429e+00  1.65499151e+00 -2.69518882e-01]\n",
            "  [-2.70369351e-01 -1.08818817e+00  1.63319349e+00 -2.74636030e-01]\n",
            "  [ 1.56663820e-01 -1.29983175e+00  1.47504294e+00 -3.31875026e-01]\n",
            "  [ 1.71783179e-01 -1.38702536e+00  1.41639841e+00 -2.01156229e-01]\n",
            "  [-2.94227928e-01 -1.22010100e+00  1.55659699e+00 -4.22679894e-02]\n",
            "  [-4.50308293e-01 -1.04213285e+00  1.63994575e+00 -1.47504598e-01]\n",
            "  [-3.82340550e-01 -1.02445543e+00  1.65596473e+00 -2.49168813e-01]\n",
            "  [-3.11610639e-01 -1.05908155e+00  1.64499319e+00 -2.74300933e-01]\n",
            "  [-2.33627483e-02 -1.22326362e+00  1.55230188e+00 -3.05675477e-01]\n",
            "  [ 2.56158352e-01 -1.39054775e+00  1.39100838e+00 -2.56618977e-01]\n",
            "  [-8.38523656e-02 -1.35454071e+00  1.46876240e+00 -3.03693656e-02]\n",
            "  [-4.90121990e-01 -1.05871499e+00  1.62278569e+00 -7.39487037e-02]\n",
            "  [-4.04308289e-01 -1.02500844e+00  1.65391803e+00 -2.24601418e-01]\n",
            "  [-3.49259257e-01 -1.03066885e+00  1.65527177e+00 -2.75343597e-01]\n",
            "  [-1.16548352e-01 -1.19197917e+00  1.57878482e+00 -2.70257384e-01]\n",
            "  [ 2.72891730e-01 -1.36526871e+00  1.40202904e+00 -3.09651971e-01]\n",
            "  [-6.98202662e-03 -1.37916267e+00  1.44711530e+00 -6.09706342e-02]\n",
            "  [-4.75757599e-01 -1.10826540e+00  1.59539080e+00 -1.13677680e-02]\n",
            "  [-4.44165200e-01 -1.01848352e+00  1.65212214e+00 -1.89473450e-01]\n",
            "  [-3.93763632e-01 -1.02176571e+00  1.65620589e+00 -2.40676701e-01]\n",
            "  [-3.16034257e-01 -1.07475710e+00  1.63822854e+00 -2.47437283e-01]\n",
            "  [ 3.69524568e-01 -1.38753200e+00  1.35162902e+00 -3.33621562e-01]\n",
            "  [ 1.36527225e-01 -1.40461230e+00  1.41005862e+00 -1.41973466e-01]\n",
            "  [-3.89592975e-01 -1.20981872e+00  1.54317594e+00  5.62357008e-02]\n",
            "  [-5.00423968e-01 -1.01199770e+00  1.64551532e+00 -1.33093521e-01]\n",
            "  [-4.14678335e-01 -1.01044416e+00  1.65901661e+00 -2.33894140e-01]\n",
            "  [-3.38154167e-01 -1.04087818e+00  1.65163827e+00 -2.72606045e-01]\n",
            "  [ 2.05172524e-01 -1.37089622e+00  1.41925025e+00 -2.53526449e-01]\n",
            "  [ 3.46455842e-01 -1.45140839e+00  1.31501126e+00 -2.10058719e-01]\n",
            "  [-2.85575956e-01 -1.32468235e+00  1.46361017e+00  1.46648005e-01]\n",
            "  [-5.80591202e-01 -1.02527368e+00  1.61605132e+00 -1.01863146e-02]\n",
            "  [-4.80877995e-01 -9.94549155e-01  1.65727413e+00 -1.81846946e-01]\n",
            "  [-4.09551620e-01 -1.00841224e+00  1.66031253e+00 -2.42348760e-01]\n",
            "  [-7.45644867e-02 -1.30373275e+00  1.50916934e+00 -1.30872220e-01]\n",
            "  [ 4.34550613e-01 -1.44751596e+00  1.28198624e+00 -2.69020975e-01]\n",
            "  [-8.14575404e-02 -1.42104518e+00  1.40134203e+00  1.01160571e-01]\n",
            "  [-6.16696000e-01 -1.06604564e+00  1.57192600e+00  1.10815346e-01]\n",
            "  [-5.22861302e-01 -9.88344431e-01  1.65224051e+00 -1.41034767e-01]\n",
            "  [-4.39545214e-01 -9.95042026e-01  1.66272187e+00 -2.28134722e-01]\n",
            "  [-4.21216190e-01 -1.06325877e+00  1.63392770e+00 -1.49452657e-01]\n",
            "  [ 4.74874705e-01 -1.44609857e+00  1.26396072e+00 -2.92736858e-01]\n",
            "  [ 1.42210633e-01 -1.47922432e+00  1.33853149e+00 -1.51764974e-03]\n",
            "  [-5.78791976e-01 -1.15390623e+00  1.51147544e+00  2.21222758e-01]]\n",
            "\n",
            " [[-5.80818057e-01 -1.05067766e+00  1.59927678e+00  3.22189480e-02]\n",
            "  [-3.35289448e-01 -1.25049388e+00  1.52312779e+00  6.26555979e-02]\n",
            "  [ 1.87273964e-01 -1.40848732e+00  1.39654863e+00 -1.75335184e-01]\n",
            "  [ 6.07372187e-02 -1.36397398e+00  1.45370042e+00 -1.50463715e-01]\n",
            "  [-4.14322376e-01 -1.08567023e+00  1.62311327e+00 -1.23120710e-01]\n",
            "  [-4.15343076e-01 -1.03369749e+00  1.64893854e+00 -1.99897915e-01]\n",
            "  [-3.25024247e-01 -1.05137217e+00  1.64781833e+00 -2.71421850e-01]\n",
            "  [-1.87632650e-01 -1.15027869e+00  1.60347390e+00 -2.65562415e-01]\n",
            "  [ 3.50670964e-01 -1.37070107e+00  1.36965930e+00 -3.49629253e-01]\n",
            "  [ 1.23663969e-01 -1.36440122e+00  1.44298661e+00 -2.02249408e-01]\n",
            "  [-3.44953746e-01 -1.16714835e+00  1.58537126e+00 -7.32692406e-02]\n",
            "  [-4.05375272e-01 -1.03919399e+00  1.64758325e+00 -2.03014076e-01]\n",
            "  [-3.54283154e-01 -1.04242599e+00  1.65030837e+00 -2.53599077e-01]\n",
            "  [-3.04689974e-01 -1.07377934e+00  1.63899028e+00 -2.60521054e-01]\n",
            "  [ 1.56983778e-01 -1.29687774e+00  1.47652924e+00 -3.36635292e-01]\n",
            "  [ 3.20030779e-01 -1.40007615e+00  1.36285806e+00 -2.82812655e-01]\n",
            "  [-2.76533455e-01 -1.22814894e+00  1.55332267e+00 -4.86403592e-02]\n",
            "  [-4.36483443e-01 -1.05123520e+00  1.63765228e+00 -1.49933815e-01]\n",
            "  [-3.87509197e-01 -1.03329837e+00  1.65188742e+00 -2.31079787e-01]\n",
            "  [-2.99814224e-01 -1.05521452e+00  1.64668441e+00 -2.91655630e-01]\n",
            "  [ 1.69456452e-01 -1.29790115e+00  1.47252882e+00 -3.44084114e-01]\n",
            "  [ 3.41893375e-01 -1.40424526e+00  1.35181808e+00 -2.89466232e-01]\n",
            "  [-1.15282439e-01 -1.33846927e+00  1.48136616e+00 -2.76144557e-02]\n",
            "  [-4.69810396e-01 -1.05625749e+00  1.62881553e+00 -1.02747671e-01]\n",
            "  [-4.10489082e-01 -1.02639341e+00  1.65270531e+00 -2.15822801e-01]\n",
            "  [-3.56334686e-01 -1.03856707e+00  1.65179026e+00 -2.56888568e-01]\n",
            "  [-1.03398442e-01 -1.19465315e+00  1.57629097e+00 -2.78239548e-01]\n",
            "  [ 2.89505482e-01 -1.36348927e+00  1.39732957e+00 -3.23345780e-01]\n",
            "  [ 1.49394527e-01 -1.41613603e+00  1.39819753e+00 -1.31455973e-01]\n",
            "  [-4.43777621e-01 -1.15034056e+00  1.57460964e+00  1.95086412e-02]\n",
            "  [-4.39566225e-01 -1.02204657e+00  1.65114462e+00 -1.89531893e-01]\n",
            "  [-3.85609508e-01 -1.02712071e+00  1.65463281e+00 -2.41902724e-01]\n",
            "  [-2.99102962e-01 -1.08861518e+00  1.63262725e+00 -2.44909257e-01]\n",
            "  [ 3.09975624e-01 -1.35699332e+00  1.39366937e+00 -3.46651822e-01]\n",
            "  [ 1.75492555e-01 -1.42623103e+00  1.38460958e+00 -1.33871064e-01]\n",
            "  [-4.02506649e-01 -1.20416486e+00  1.54403710e+00  6.26344085e-02]\n",
            "  [-5.03391862e-01 -1.02320707e+00  1.63919616e+00 -1.12597242e-01]\n",
            "  [-3.95262629e-01 -1.02247632e+00  1.65578973e+00 -2.38050789e-01]\n",
            "  [-3.34663272e-01 -1.04170179e+00  1.65142322e+00 -2.75058240e-01]\n",
            "  [ 3.36993158e-01 -1.35243154e+00  1.38572955e+00 -3.70291024e-01]\n",
            "  [ 2.79641330e-01 -1.42322409e+00  1.35993528e+00 -2.16352582e-01]\n",
            "  [-1.96850985e-01 -1.35579753e+00  1.45370972e+00  9.89388600e-02]\n",
            "  [-5.40197551e-01 -1.02227223e+00  1.63049567e+00 -6.80258721e-02]\n",
            "  [-4.60449904e-01 -1.00679135e+00  1.65502095e+00 -1.87779725e-01]\n",
            "  [-4.02611583e-01 -1.02067840e+00  1.65590155e+00 -2.32611448e-01]\n",
            "  [-2.07443684e-01 -1.17813563e+00  1.58974206e+00 -2.04162687e-01]\n",
            "  [ 4.98044670e-01 -1.43241191e+00  1.26204979e+00 -3.27682585e-01]\n",
            "  [-8.30652714e-02 -1.39063525e+00  1.43446577e+00  3.92346866e-02]\n",
            "  [-5.54712713e-01 -1.05181026e+00  1.60809982e+00 -1.57693028e-03]\n",
            "  [-5.12162387e-01 -9.99419689e-01  1.64921391e+00 -1.37631655e-01]\n",
            "  [-4.14514840e-01 -1.00374830e+00  1.66174126e+00 -2.43477970e-01]\n",
            "  [-3.80099267e-01 -1.05874276e+00  1.64122736e+00 -2.02385277e-01]\n",
            "  [ 5.54535627e-01 -1.41875088e+00  1.24025369e+00 -3.76038462e-01]\n",
            "  [ 1.27517670e-01 -1.45678306e+00  1.36393487e+00 -3.46694514e-02]\n",
            "  [-5.95293820e-01 -1.13898277e+00  1.51694000e+00  2.17336595e-01]]], shape=(2, 55, 4), dtype=float32)\n",
            "--------------------\n",
            "decoder_layer1_block1.shape: (2, 2, 55, 55)\n",
            "decoder_layer1_block2.shape: (2, 2, 55, 10)\n",
            "decoder_layer2_block1.shape: (2, 2, 55, 55)\n",
            "decoder_layer2_block2.shape: (2, 2, 55, 10)\n"
          ]
        }
      ],
      "source": [
        "# 超參數\n",
        "num_layers = 2 # 2 層的 Decoder\n",
        "d_model = 4\n",
        "num_heads = 2\n",
        "dff = 8\n",
        "target_vocab_size = subword_encoder_zh.vocab_size + 2 # 記得加上 <start>, <end>\n",
        "\n",
        "# 遮罩\n",
        "inp_padding_mask = create_padding_mask(inp)\n",
        "tar_padding_mask = create_padding_mask(tar)\n",
        "look_ahead_mask = create_look_ahead_mask(tar.shape[1])\n",
        "combined_mask = tf.math.maximum(tar_padding_mask, look_ahead_mask)\n",
        "\n",
        "# 初始化一個 Decoder\n",
        "decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size)\n",
        "\n",
        "# 將 2 維的索引序列以及遮罩丟入 Decoder\n",
        "print(\"tar:\", tar)\n",
        "print(\"-\" * 20)\n",
        "print(\"combined_mask:\", combined_mask)\n",
        "print(\"-\" * 20)\n",
        "print(\"enc_out:\", enc_out)\n",
        "print(\"-\" * 20)\n",
        "print(\"inp_padding_mask:\", inp_padding_mask)\n",
        "print(\"-\" * 20)\n",
        "dec_out, attn = decoder(tar, enc_out, training=False, \n",
        "                        combined_mask=combined_mask,\n",
        "                        inp_padding_mask=inp_padding_mask)\n",
        "print(\"dec_out:\", dec_out)\n",
        "print(\"-\" * 20)\n",
        "for block_name, attn_weights in attn.items():\n",
        "  print(f\"{block_name}.shape: {attn_weights.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "9a9yk0woD8-2"
      },
      "outputs": [],
      "source": [
        "# Transformer 之上已經沒有其他 layers 了，我們使用 tf.keras.Model 建立一個模型\n",
        "class Transformer(tf.keras.Model):\n",
        "  # 初始參數包含 Encoder & Decoder 都需要超參數以及中英字典數目\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
        "               target_vocab_size, rate=0.1):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
        "                           input_vocab_size, rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
        "                           target_vocab_size, rate)\n",
        "    # 這個 FFN 輸出跟中文字典一樣大的 logits 數，等通過 softmax 就代表每個中文字的出現機率\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "  \n",
        "  # enc_padding_mask 跟 dec_padding_mask 都是英文序列的 padding mask，\n",
        "  # 只是一個給 Encoder layer 的 MHA 用，一個是給 Decoder layer 的 MHA 2 使用\n",
        "  def call(self, inp, tar, training, enc_padding_mask, \n",
        "           combined_mask, dec_padding_mask):\n",
        "\n",
        "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "    \n",
        "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "    dec_output, attention_weights = self.decoder(\n",
        "        tar, enc_output, training, combined_mask, dec_padding_mask)\n",
        "    \n",
        "    # 將 Decoder 輸出通過最後一個 linear layer\n",
        "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "    \n",
        "    return final_output, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXQdl4bMEBdX",
        "outputId": "0c8aa6b9-8bc7-42a5-dc0e-d96687fcb668"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tar: tf.Tensor(\n",
            "[[299 159 148  75 159 158 147 140 148  75 147 153 146  75 159 158 148 153\n",
            "  146  75 148 160  75 150 148  92  75 159 158 147 144 153 153  75 159 158\n",
            "  147 140 148 300   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0]\n",
            " [299 147 160 140 153  75 159 154  75 159 153 146  75 151 148  75 148 154\n",
            "  153 146  75 150 147 160 140 153  75 155 154  75 144  75 158 144 153 153\n",
            "   75 159 147 140 148  75 147 154 153 146  75 159 148  75 147 160 140 159\n",
            "  300]], shape=(2, 55), dtype=int64)\n",
            "--------------------\n",
            "tar_inp: tf.Tensor(\n",
            "[[299 159 148  75 159 158 147 140 148  75 147 153 146  75 159 158 148 153\n",
            "  146  75 148 160  75 150 148  92  75 159 158 147 144 153 153  75 159 158\n",
            "  147 140 148 300   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [299 147 160 140 153  75 159 154  75 159 153 146  75 151 148  75 148 154\n",
            "  153 146  75 150 147 160 140 153  75 155 154  75 144  75 158 144 153 153\n",
            "   75 159 147 140 148  75 147 154 153 146  75 159 148  75 147 160 140 159]], shape=(2, 54), dtype=int64)\n",
            "--------------------\n",
            "tar_real: tf.Tensor(\n",
            "[[159 148  75 159 158 147 140 148  75 147 153 146  75 159 158 148 153 146\n",
            "   75 148 160  75 150 148  92  75 159 158 147 144 153 153  75 159 158 147\n",
            "  140 148 300   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [147 160 140 153  75 159 154  75 159 153 146  75 151 148  75 148 154 153\n",
            "  146  75 150 147 160 140 153  75 155 154  75 144  75 158 144 153 153  75\n",
            "  159 147 140 148  75 147 154 153 146  75 159 148  75 147 160 140 159 300]], shape=(2, 54), dtype=int64)\n",
            "--------------------\n",
            "predictions: tf.Tensor(\n",
            "[[[ 0.0371036  -0.09082927  0.08761619 ... -0.14282139  0.30328718\n",
            "    0.02944443]\n",
            "  [ 0.05681565 -0.09030984  0.12798868 ... -0.20192894  0.24050121\n",
            "    0.16150321]\n",
            "  [ 0.08144398 -0.08480393  0.15238322 ... -0.2348526   0.16503304\n",
            "    0.24933794]\n",
            "  ...\n",
            "  [ 0.04802005 -0.0917501   0.10511958 ... -0.16824068  0.27904114\n",
            "    0.08221759]\n",
            "  [ 0.07337705 -0.08651344  0.14689095 ... -0.22791053  0.18682683\n",
            "    0.22955143]\n",
            "  [ 0.0788606  -0.08779997  0.14428017 ... -0.22320013  0.18986613\n",
            "    0.21393521]]\n",
            "\n",
            " [[ 0.04011481 -0.09098285  0.08857557 ... -0.1438465   0.29997015\n",
            "    0.03078423]\n",
            "  [ 0.05464662 -0.09061378  0.12517595 ... -0.19797711  0.24695434\n",
            "    0.15196118]\n",
            "  [ 0.07796958 -0.08426903  0.15287277 ... -0.23608096  0.16558647\n",
            "    0.25437525]\n",
            "  ...\n",
            "  [ 0.05083483 -0.09159115  0.11342346 ... -0.1805873   0.26715267\n",
            "    0.11017494]\n",
            "  [ 0.07521747 -0.08438475  0.15212214 ... -0.23537682  0.16970046\n",
            "    0.25286674]\n",
            "  [ 0.08068422 -0.08690946  0.14720674 ... -0.22729553  0.18088746\n",
            "    0.2257142 ]]], shape=(2, 54, 301), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# 超參數\n",
        "num_layers = 1\n",
        "d_model = 4\n",
        "num_heads = 2\n",
        "dff = 8\n",
        "\n",
        "# + 2 是為了 <start> & <end> token\n",
        "input_vocab_size = subword_encoder_ch.vocab_size + 2\n",
        "output_vocab_size = subword_encoder_zh.vocab_size + 2\n",
        "\n",
        "# 重點中的重點。訓練時用前一個字來預測下一個中文字\n",
        "tar_inp = tar[:, :-1]\n",
        "tar_real = tar[:, 1:]\n",
        "\n",
        "# 來源 / 目標語言用的遮罩。注意 `comined_mask` 已經將目標語言的兩種遮罩合而為一\n",
        "inp_padding_mask = create_padding_mask(inp)\n",
        "tar_padding_mask = create_padding_mask(tar_inp)\n",
        "look_ahead_mask = create_look_ahead_mask(tar_inp.shape[1])\n",
        "combined_mask = tf.math.maximum(tar_padding_mask, look_ahead_mask)\n",
        "\n",
        "# 初始化我們的第一個 transformer\n",
        "transformer = Transformer(num_layers, d_model, num_heads, dff, \n",
        "                          input_vocab_size, output_vocab_size)\n",
        "\n",
        "# 將英文、中文序列丟入取得 Transformer 預測下個中文字的結果\n",
        "predictions, attn_weights = transformer(inp, tar_inp, False, inp_padding_mask, \n",
        "                                        combined_mask, inp_padding_mask)\n",
        "\n",
        "print(\"tar:\", tar)\n",
        "print(\"-\" * 20)\n",
        "print(\"tar_inp:\", tar_inp)\n",
        "print(\"-\" * 20)\n",
        "print(\"tar_real:\", tar_real)\n",
        "print(\"-\" * 20)\n",
        "print(\"predictions:\", predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "wH_bz-9aEExw"
      },
      "outputs": [],
      "source": [
        "# ...\n",
        "\n",
        "# tar_inp = tar[:, :-1]\n",
        "# tar_real = tar[:, 1:]\n",
        "\n",
        "# predictions, attn_weights = transformer(inp, tar_inp, False, ...)\n",
        "\n",
        "# ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jl9DSe7QEVHw",
        "outputId": "8895cce5-8403-4036-b3dd-0c69eed031c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.31326166, 0.31326166, 1.3132616 ], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ],
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "# 假設我們要解的是一個 binary classifcation， 0 跟 1 個代表一個 label\n",
        "real = tf.constant([1, 1, 0], shape=(1, 3), dtype=tf.float32)\n",
        "pred = tf.constant([[0, 1], [0, 1], [0, 1]], dtype=tf.float32)\n",
        "loss_object(real, pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuzXg3l2EXI6",
        "outputId": "31d890b4-dbcf-4940-a8e3-34195b672ab7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predictions: tf.Tensor(\n",
            "[[[ 0.0371036  -0.09082927  0.08761619 ... -0.14282139  0.30328718\n",
            "    0.02944443]\n",
            "  [ 0.05681565 -0.09030984  0.12798868 ... -0.20192894  0.24050121\n",
            "    0.16150321]\n",
            "  [ 0.08144398 -0.08480393  0.15238322 ... -0.2348526   0.16503304\n",
            "    0.24933794]\n",
            "  ...\n",
            "  [ 0.04802005 -0.0917501   0.10511958 ... -0.16824068  0.27904114\n",
            "    0.08221759]\n",
            "  [ 0.07337705 -0.08651344  0.14689095 ... -0.22791053  0.18682683\n",
            "    0.22955143]\n",
            "  [ 0.0788606  -0.08779997  0.14428017 ... -0.22320013  0.18986613\n",
            "    0.21393521]]\n",
            "\n",
            " [[ 0.04011481 -0.09098285  0.08857557 ... -0.1438465   0.29997015\n",
            "    0.03078423]\n",
            "  [ 0.05464662 -0.09061378  0.12517595 ... -0.19797711  0.24695434\n",
            "    0.15196118]\n",
            "  [ 0.07796958 -0.08426903  0.15287277 ... -0.23608096  0.16558647\n",
            "    0.25437525]\n",
            "  ...\n",
            "  [ 0.05083483 -0.09159115  0.11342346 ... -0.1805873   0.26715267\n",
            "    0.11017494]\n",
            "  [ 0.07521747 -0.08438475  0.15212214 ... -0.23537682  0.16970046\n",
            "    0.25286674]\n",
            "  [ 0.08068422 -0.08690946  0.14720674 ... -0.22729553  0.18088746\n",
            "    0.2257142 ]]], shape=(2, 54, 301), dtype=float32)\n",
            "--------------------\n",
            "tf.Tensor(\n",
            "[[1.2879632 1.53492   1.6882898 1.6691622 1.5745713 1.4696263 1.2879927\n",
            "  1.4460504 1.6434246 1.6697924 1.5799927 1.4931198 1.3209118 1.3923525\n",
            "  1.5931861 1.6673036 1.613503  1.5226732 1.370242  1.331116  1.5534213\n",
            "  1.6711428 1.6523051 1.5676801 1.4083136 1.2868705 1.4973822 1.6504402\n",
            "  1.664781  1.5743349 1.479205  1.3035665 1.3880848 1.6448795 1.6702172\n",
            "  1.6236506 1.516095  1.3462925 1.2712623 1.6016524 1.6661994 1.6260501\n",
            "  1.5383741 1.3930365 1.2543967 1.5017178 1.6635631 1.6496629 1.5682569\n",
            "  1.4469235 1.2787592 1.4135811 1.6482296 1.668206 ]\n",
            " [1.3047872 1.5169752 1.6728777 1.6542313 1.5788842 1.4901792 1.3202859\n",
            "  1.4250464 1.6426792 1.655553  1.5972589 1.507756  1.3756211 1.3241699\n",
            "  1.606308  1.6730832 1.6195259 1.5295794 1.3833848 1.2976437 1.5661974\n",
            "  1.67097   1.6294152 1.5724049 1.432652  1.2915289 1.5033405 1.6496172\n",
            "  1.6529666 1.6065886 1.4955142 1.3657708 1.416964  1.6376885 1.6742163\n",
            "  1.619689  1.5466683 1.3877459 1.3040829 1.5932437 1.6800423 1.6571451\n",
            "  1.553922  1.410399  1.279156  1.5345    1.683747  1.6643512 1.5846825\n",
            "  1.5102959 1.315199  1.4592762 1.660208  1.6804187]], shape=(2, 54), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "print(\"predictions:\", predictions)\n",
        "print(\"-\" * 20)\n",
        "print(tf.reduce_sum(predictions, axis=-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "fi_2r_ggEZDc"
      },
      "outputs": [],
      "source": [
        "def loss_function(real, pred):\n",
        "  # 這次的 mask 將序列中不等於 0 的位置視為 1，其餘為 0 \n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  # 照樣計算所有位置的 cross entropy 但不加總\n",
        "  loss_ = loss_object(real, pred)\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask  # 只計算非 <pad> 位置的損失 \n",
        "  \n",
        "  return tf.reduce_mean(loss_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "AjNfgBPOEaSM"
      },
      "outputs": [],
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "    name='train_accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TA2lmrtEEcFG",
        "outputId": "841e97b1-ca11-46b5-c5a7-4368ff5caa10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_vocab_size: 8437\n",
            "target_vocab_size: 301\n"
          ]
        }
      ],
      "source": [
        "num_layers = 4 \n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "\n",
        "input_vocab_size = subword_encoder_ch.vocab_size + 2\n",
        "target_vocab_size = subword_encoder_zh.vocab_size + 2\n",
        "dropout_rate = 0.1  # 預設值\n",
        "\n",
        "print(\"input_vocab_size:\", input_vocab_size)\n",
        "print(\"target_vocab_size:\", target_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "DZnTWjd0EZCB"
      },
      "outputs": [],
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  # 論文預設 `warmup_steps` = 4000\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "    \n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "    \n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "    \n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "  \n",
        "# 將客製化 learning rate schdeule 丟入 Adam opt.\n",
        "# Adam opt. 的參數都跟論文相同\n",
        "learning_rate = CustomSchedule(d_model)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
        "                                     epsilon=1e-9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "I8tuv8SIEhr0",
        "outputId": "535f07c9-7ff9-44e6-b61a-08f26ab7572d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "metadata": {},
          "execution_count": 177
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "d_models = [128, 256, 512]\n",
        "warmup_steps = [1000 * i for i in range(1, 4)]\n",
        "\n",
        "schedules = []\n",
        "labels = []\n",
        "colors = [\"blue\", \"red\", \"black\"]\n",
        "for d in d_models:\n",
        "  schedules += [CustomSchedule(d, s) for s in warmup_steps]\n",
        "  labels += [f\"d_model: {d}, warm: {s}\" for s in warmup_steps]\n",
        "\n",
        "for i, (schedule, label) in enumerate(zip(schedules, labels)):\n",
        "  plt.plot(schedule(tf.range(10000, dtype=tf.float32)), \n",
        "           label=label, color=colors[i // 3])\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBVY64v9Ee58",
        "outputId": "144ff5b8-50f1-4ce1-bbb8-d8b87b863cef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "這個 Transformer 有 4 層 Encoder / Decoder layers\n",
            "d_model: 128\n",
            "num_heads: 8\n",
            "dff: 512\n",
            "input_vocab_size: 8437\n",
            "target_vocab_size: 301\n",
            "dropout_rate: 0.1\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
        "                          input_vocab_size, target_vocab_size, dropout_rate)\n",
        "\n",
        "print(f\"\"\"這個 Transformer 有 {num_layers} 層 Encoder / Decoder layers\n",
        "d_model: {d_model}\n",
        "num_heads: {num_heads}\n",
        "dff: {dff}\n",
        "input_vocab_size: {input_vocab_size}\n",
        "target_vocab_size: {target_vocab_size}\n",
        "dropout_rate: {dropout_rate}\n",
        "\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7n9npw9EnyY",
        "outputId": "78b36ac3-abae-4c45-9ee6-2a4330e96602"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "已讀取最新的 checkpoint，模型已訓練 150 epochs。\n"
          ]
        }
      ],
      "source": [
        "train_perc = 10\n",
        "val_prec = 1\n",
        "drop_prec = 100 - train_perc - val_prec\n",
        "\n",
        "# 方便比較不同實驗/ 不同超參數設定的結果\n",
        "run_id = f\"{num_layers}layers_{d_model}d_{num_heads}heads_{dff}dff_{train_perc}train_perc\"\n",
        "checkpoint_path = os.path.join(checkpoint_path, run_id)\n",
        "log_dir = os.path.join(log_dir, run_id)\n",
        "\n",
        "# tf.train.Checkpoint 可以幫我們把想要存下來的東西整合起來，方便儲存與讀取\n",
        "# 一般來說你會想存下模型以及 optimizer 的狀態\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "# ckpt_manager 會去 checkpoint_path 看有沒有符合 ckpt 裡頭定義的東西\n",
        "# 存檔的時候只保留最近 5 次 checkpoints，其他自動刪除\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "# 如果在 checkpoint 路徑上有發現檔案就讀進來\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "  \n",
        "  # 用來確認之前訓練多少 epochs 了\n",
        "  last_epoch = int(ckpt_manager.latest_checkpoint.split(\"-\")[-1])\n",
        "  print(f'已讀取最新的 checkpoint，模型已訓練 {last_epoch} epochs。')\n",
        "else:\n",
        "  last_epoch = 0\n",
        "  print(\"沒找到 checkpoint，從頭訓練。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "RVVTnSmBFn3s"
      },
      "outputs": [],
      "source": [
        "# 為 Transformer 的 Encoder / Decoder 準備遮罩\n",
        "def create_masks(inp, tar):\n",
        "  # 中文句子的 padding mask，要交給 Encoder layer 自注意力機制用的\n",
        "  enc_padding_mask = create_padding_mask(inp)\n",
        "  \n",
        "  # 同樣也是中文句子的 padding mask，但是是要交給 Decoder layer 的 MHA 2 \n",
        "  # 關注 Encoder 輸出序列用的\n",
        "  dec_padding_mask = create_padding_mask(inp)\n",
        "  \n",
        "  # Decoder layer 的 MHA1 在做自注意力機制用的\n",
        "  # `combined_mask` 是台語句子的 padding mask 跟 look ahead mask 的疊加\n",
        "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "  dec_target_padding_mask = create_padding_mask(tar)\n",
        "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "  \n",
        "  return enc_padding_mask, combined_mask, dec_padding_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "id": "U7ZTTcJMFos_"
      },
      "outputs": [],
      "source": [
        "@tf.function  # 讓 TensorFlow 幫我們將 eager code 優化並加快運算\n",
        "def train_step(inp, tar):\n",
        "  # 前面說過的，用去尾的原始序列去預測下一個字的序列\n",
        "  tar_inp = tar[:, :-1]\n",
        "  tar_real = tar[:, 1:]\n",
        "  \n",
        "  # 建立 3 個遮罩\n",
        "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "  \n",
        "  # 紀錄 Transformer 的所有運算過程以方便之後做梯度下降\n",
        "  with tf.GradientTape() as tape:\n",
        "    # 注意是丟入 `tar_inp` 而非 `tar`。記得將 `training` 參數設定為 True\n",
        "    predictions, _ = transformer(inp, tar_inp, \n",
        "                                 True, \n",
        "                                 enc_padding_mask, \n",
        "                                 combined_mask, \n",
        "                                 dec_padding_mask)\n",
        "    # 跟影片中顯示的相同，計算左移一個字的序列跟模型預測分佈之間的差異，當作 loss\n",
        "    loss = loss_function(tar_real, predictions)\n",
        "\n",
        "  # 取出梯度並呼叫前面定義的 Adam optimizer 幫我們更新 Transformer 裡頭可訓練的參數\n",
        "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
        "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "  \n",
        "  # 將 loss 以及訓練 acc 記錄到 TensorBoard 上，非必要\n",
        "  train_loss(loss)\n",
        "  train_accuracy(tar_real, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mW92mWOFuEO",
        "outputId": "4c7af026-9324-4d51-b68f-3cbece0e181a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "此超參數組合的 Transformer 已經訓練 150 epochs。\n",
            "剩餘 epochs：0\n"
          ]
        }
      ],
      "source": [
        "# 定義我們要看幾遍數據集\n",
        "EPOCHS = 150\n",
        "print(f\"此超參數組合的 Transformer 已經訓練 {last_epoch} epochs。\")\n",
        "print(f\"剩餘 epochs：{min(0, last_epoch - EPOCHS)}\")\n",
        "\n",
        "\n",
        "# 用來寫資訊到 TensorBoard，非必要但十分推薦\n",
        "summary_writer = tf.summary.create_file_writer(log_dir)\n",
        "\n",
        "# 比對設定的 `EPOCHS` 以及已訓練的 `last_epoch` 來決定還要訓練多少 epochs\n",
        "for epoch in range(last_epoch, EPOCHS):\n",
        "  start = time.time()\n",
        "  \n",
        "  # 重置紀錄 TensorBoard 的 metrics\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  \n",
        "  # 一個 epoch 就是把我們定義的訓練資料集一個一個 batch 拿出來處理，直到看完整個數據集 \n",
        "  for (step_idx, (inp, tar)) in enumerate(train_dataset):\n",
        "    \n",
        "    # 每次 step 就是將數據丟入 Transformer，讓它生預測結果並計算梯度最小化 loss\n",
        "    train_step(inp, tar)  \n",
        "\n",
        "  # 每個 epoch 完成就存一次檔    \n",
        "  if (epoch + 1) % 1 == 0:\n",
        "    ckpt_save_path = ckpt_manager.save()\n",
        "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
        "                                                         ckpt_save_path))\n",
        "    \n",
        "  # 將 loss 以及 accuracy 寫到 TensorBoard 上\n",
        "  with summary_writer.as_default():\n",
        "    tf.summary.scalar(\"train_loss\", train_loss.result(), step=epoch + 1)\n",
        "    tf.summary.scalar(\"train_acc\", train_accuracy.result(), step=epoch + 1)\n",
        "  \n",
        "  print('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
        "                                                train_loss.result(), \n",
        "                                                train_accuracy.result()))\n",
        "  print('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "PV8QmxzvFxTF"
      },
      "outputs": [],
      "source": [
        "# # 87 分，不能再高了。\n",
        "# for epoch in range(EPOCHS):\n",
        "#   for inp, tar in train_dataset:\n",
        "#     train_step(inp, tar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "gO6lVcNcF0sV"
      },
      "outputs": [],
      "source": [
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir {your_log_dir}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "id": "3qR4MCwLGCcI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df5108dc-0948-4cd9-99e6-c51512429263"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
          ]
        }
      ],
      "source": [
        "# 給定一個英文句子，輸出預測的中文索引數字序列以及注意權重 dict\n",
        "def evaluate(inp_sentence):\n",
        "  \n",
        "  # 準備英文句子前後會加上的 <start>, <end>\n",
        "  start_token = [subword_encoder_ch.vocab_size]\n",
        "  end_token = [subword_encoder_ch.vocab_size + 1]\n",
        "  \n",
        "  # inp_sentence 是字串，我們用 Subword Tokenizer 將其變成子詞的索引序列\n",
        "  # 並在前後加上 BOS / EOS\n",
        "  inp_sentence = start_token + subword_encoder_ch.encode(inp_sentence) + end_token\n",
        "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
        "  \n",
        "  # 跟我們在影片裡看到的一樣，Decoder 在第一個時間點吃進去的輸入\n",
        "  # 是一個只包含一個中文 <start> token 的序列\n",
        "  decoder_input = [subword_encoder_zh.vocab_size]\n",
        "  output = tf.expand_dims(decoder_input, 0)  # 增加 batch 維度\n",
        "  \n",
        "  # auto-regressive，一次生成一個中文字並將預測加到輸入再度餵進 Transformer\n",
        "  for i in range(MAX_LENGTH):\n",
        "    # 每多一個生成的字就得產生新的遮罩\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "        encoder_input, output)\n",
        "  \n",
        "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "    predictions, attention_weights = transformer(encoder_input, \n",
        "                                                 output,\n",
        "                                                 False,\n",
        "                                                 enc_padding_mask,\n",
        "                                                 combined_mask,\n",
        "                                                 dec_padding_mask)\n",
        "    \n",
        "\n",
        "    # 將序列中最後一個 distribution 取出，並將裡頭值最大的當作模型最新的預測字\n",
        "    predictions = predictions[: , -1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "    \n",
        "    # 遇到 <end> token 就停止回傳，代表模型已經產生完結果\n",
        "    if tf.equal(predicted_id, subword_encoder_zh.vocab_size + 1):\n",
        "      return tf.squeeze(output, axis=0), attention_weights\n",
        "    \n",
        "    #將 Transformer 新預測的中文索引加到輸出序列中，讓 Decoder 可以在產生\n",
        "    # 下個中文字的時候關注到最新的 `predicted_id`\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  # 將 batch 的維度去掉後回傳預測的中文索引序列\n",
        "  return tf.squeeze(output, axis=0), attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "HHK3DjceGFL3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b20cee04-97f3-457b-b426-9096b7ace6b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence: 反倒轉利用環保的生態防治法\n",
            "--------------------\n",
            "predicted_seq: tf.Tensor(\n",
            "[299 155 148 140 153  93  88 159 154  93  88 151 148  98  88 148 154 153\n",
            " 146  98  75 155 147 160 140 153  98  88 159 140 148  96  75 147 154 153\n",
            " 146  96  75   2], shape=(40,), dtype=int32)\n",
            "--------------------\n",
            "predicted_sentence: pian2-to2-li7-iong7 phuan7-tai5 hong5 。\n"
          ]
        }
      ],
      "source": [
        "# 要被翻譯的英文句子\n",
        "sentence = \"反倒轉利用環保的生態防治法\"\n",
        "\n",
        "# 取得預測的中文索引序列\n",
        "predicted_seq, _ = evaluate(sentence)\n",
        "\n",
        "# 過濾掉 <start> & <end> tokens 並用中文的 subword tokenizer 幫我們將索引序列還原回中文句子\n",
        "target_vocab_size = subword_encoder_zh.vocab_size\n",
        "predicted_seq_without_bos_eos = [idx for idx in predicted_seq if idx < target_vocab_size]\n",
        "predicted_sentence = subword_encoder_zh.decode(predicted_seq_without_bos_eos)\n",
        "\n",
        "print(\"sentence:\", sentence)\n",
        "print(\"-\" * 20)\n",
        "print(\"predicted_seq:\", predicted_seq)\n",
        "print(\"-\" * 20)\n",
        "print(\"predicted_sentence:\", predicted_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv(test_x_path, sep=\",\", header=None)#, quoting=2\n",
        "#metadata_df.head(3)\n",
        "test.columns = [\"id\", \"txt\"]\n",
        "test = test[[\"id\", \"txt\"]]\n",
        "test = test.drop(0)\n",
        "\n",
        "test_x = test[\"txt\"].values\n",
        "print(len(test_x))\n",
        "submit_ans = []\n",
        "count = 1\n",
        "for i in test_x:\n",
        "    # 取得預測的中文索引序列\n",
        "  predicted_seq, _ = evaluate(i)\n",
        "\n",
        "  # 過濾掉 <start> & <end> tokens 並用中文的 subword tokenizer 幫我們將索引序列還原回中文句子\n",
        "  target_vocab_size = subword_encoder_zh.vocab_size\n",
        "  predicted_seq_without_bos_eos = [idx for idx in predicted_seq if idx < target_vocab_size]\n",
        "  predicted_sentence = subword_encoder_zh.decode(predicted_seq_without_bos_eos)\n",
        "\n",
        "  # print(\"sentence:\", i)\n",
        "  print(count)\n",
        "  # print(\"-\" * 20)\n",
        "  #print(\"predicted_seq:\", predicted_seq)\n",
        "  # # print(\"-\" * 20)\n",
        "  print(\"predicted_sentence:\", predicted_sentence)\n",
        "  submit_ans.append(predicted_sentence)\n",
        "  count = count + 1\n",
        "\n",
        "\n",
        "\n",
        "#MAE(valid_y,submit_ans)\n"
      ],
      "metadata": {
        "id": "HVskk5gTWBnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lM-vLl5pD3J"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "# co_id_np = np.array(co_id)\n",
        "# year_np = np.array(year)\n",
        "\n",
        "# data = np.array([co_id_np, year_np])\n",
        "\n",
        "# np.savetxt(\"sample.csv\", data.T, fmt='%s', delimiter='\\t')\n",
        "test_id = list(range(1,641+1))    \n",
        "#with open('submit.csv', 'w', newline='',encoding='UTF-8-sig') as test_file:\n",
        "\n",
        "# !ls\n",
        "with open('311581024.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow(['id', 'txt'])\n",
        "    for x,y in zip (test_id,submit_ans):\n",
        "        writer.writerow([x,y])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUFeZq56GF32"
      },
      "outputs": [],
      "source": [
        "transformer.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuT8X8lPGKk5"
      },
      "outputs": [],
      "source": [
        "predicted_seq, attention_weights = evaluate(sentence)\n",
        "\n",
        "# 在這邊我們自動選擇最後一個 Decoder layer 的 MHA 2，也就是 Decoder 關注 Encoder 的 MHA\n",
        "layer_name = f\"decoder_layer{num_layers}_block2\"\n",
        "\n",
        "print(\"sentence:\", sentence)\n",
        "print(\"-\" * 20)\n",
        "print(\"predicted_seq:\", predicted_seq)\n",
        "print(\"-\" * 20)\n",
        "print(\"attention_weights.keys():\")\n",
        "for layer_name, attn in attention_weights.items():\n",
        "  print(f\"{layer_name}.shape: {attn.shape}\")\n",
        "print(\"-\" * 20)\n",
        "print(\"layer_name:\", layer_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sslkY6ImGNhl"
      },
      "outputs": [],
      "source": [
        "# import matplotlib as mpl\n",
        "# # 你可能會需要自行下載一個中文字體檔案以讓 matplotlib 正確顯示中文\n",
        "# zhfont = mpl.font_manager.FontProperties(fname='/usr/share/fonts/SimHei/simhei.ttf')\n",
        "# plt.style.use(\"seaborn-whitegrid\")\n",
        "\n",
        "# # 這個函式將英 -> 中翻譯的注意權重視覺化（注意：我們將注意權重 transpose 以最佳化渲染結果\n",
        "# def plot_attention_weights(attention_weights, sentence, predicted_seq, layer_name, max_len_tar=None):\n",
        "    \n",
        "#   fig = plt.figure(figsize=(17, 7))\n",
        "  \n",
        "#   sentence = subword_encoder_ch.encode(sentence)\n",
        "  \n",
        "#   # 只顯示中文序列前 `max_len_tar` 個字以避免畫面太過壅擠\n",
        "#   if max_len_tar:\n",
        "#     predicted_seq = predicted_seq[:max_len_tar]\n",
        "#   else:\n",
        "#     max_len_tar = len(predicted_seq)\n",
        "  \n",
        "#   # 將某一個特定 Decoder layer 裡頭的 MHA 1 或 MHA2 的注意權重拿出來並去掉 batch 維度\n",
        "#   attention_weights = tf.squeeze(attention_weights[layer_name], axis=0)  \n",
        "#   # (num_heads, tar_seq_len, inp_seq_len)\n",
        "  \n",
        "#   # 將每個 head 的注意權重畫出\n",
        "#   for head in range(attention_weights.shape[0]):\n",
        "#     ax = fig.add_subplot(2, 4, head + 1)\n",
        "\n",
        "#     # [注意]我為了將長度不短的英文子詞顯示在 y 軸，將注意權重做了 transpose\n",
        "#     attn_map = np.transpose(attention_weights[head][:max_len_tar, :])\n",
        "#     ax.matshow(attn_map, cmap='viridis')  # (inp_seq_len, tar_seq_len)\n",
        "    \n",
        "#     fontdict = {\"fontproperties\": zhfont}\n",
        "    \n",
        "#     ax.set_xticks(range(max(max_len_tar, len(predicted_seq))))\n",
        "#     ax.set_xlim(-0.5, max_len_tar -1.5)\n",
        "    \n",
        "#     ax.set_yticks(range(len(sentence) + 2))\n",
        "#     ax.set_xticklabels([subword_encoder_zh.decode([i]) for i in predicted_seq \n",
        "#                         if i < subword_encoder_zh.vocab_size], \n",
        "#                        fontdict=fontdict, fontsize=18)    \n",
        "    \n",
        "#     ax.set_yticklabels(\n",
        "#         ['<start>'] + [subword_encoder_ch.decode([i]) for i in sentence] + ['<end>'], \n",
        "#         fontdict=fontdict)\n",
        "    \n",
        "#     ax.set_xlabel('Head {}'.format(head + 1))\n",
        "#     ax.tick_params(axis=\"x\", labelsize=12)\n",
        "#     ax.tick_params(axis=\"y\", labelsize=12)\n",
        "  \n",
        "#   plt.tight_layout()\n",
        "#   plt.show()\n",
        "#   plt.close(fig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMhl5nFAGSHm"
      },
      "outputs": [],
      "source": [
        "# plot_attention_weights(attention_weights, sentence, \n",
        "#                        predicted_seq, layer_name, max_len_tar=18)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/drive/MyDrive/nycu/2022ML/translate/ml-2022-nycu-translation\")\n",
        "!pip install pipreqs\n",
        "!pipreqs --force\n",
        "!pip freeze > requirements.txt\n",
        "import sys\n",
        "print(sys.modules.keys())"
      ],
      "metadata": {
        "id": "4Lw3StKpke6E"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}